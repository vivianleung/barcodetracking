{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# USER INPUTS\n",
    "\n",
    "\n",
    "\"\"\"Experiment name to prepend output files\"\"\"\n",
    "EXPERIMENT = \"sample_graphing-2\"\n",
    "\n",
    "\"\"\"Directory path to input data \n",
    "    (filtered; output from '1-read_fastq_id_features)\n",
    "\"\"\"\n",
    "# FILTERED_FILEPATH = \"../output/filtered-sample-all.csv\"\n",
    "FILTERED_FILEPATH = '../../../2016-09-19-validation_graphs_redoes/data/filtered-ratios.csv'\n",
    "\"\"\"Directory path to save output\"\"\"\n",
    "OUTPUT_DIRECTORY = \"../output\"\n",
    "\n",
    "\"\"\"Minimum number of reads as a baseline. Used to simplify data processing.\"\"\"\n",
    "MIN_READS = 100\n",
    "\n",
    "# PRESETS AND SCRIPT\n",
    "\n",
    "\"\"\"\n",
    "# NEED TO FIGURE HOW TO RELOAD DEPENDENT FUNCTIONS\n",
    "UPON VALUE CHANGES\n",
    "Column names correspoinding to eponymous variables\"\"\"\n",
    "\n",
    "SAMPLE = 'idx'\n",
    "QTAG = 'qtag'\n",
    "BARCODE = 'barcode'\n",
    "READS = 'readsPF'\n",
    "MCOUNTS = 'mcountsPF'\n",
    "PERCENT_MCOUNTS = 'percent_%s'%MCOUNTS\n",
    "GROUPBY = ['idx']# for older versions/ formats\n",
    "\n",
    "def check_inputs():\n",
    "    \n",
    "    # modules\n",
    "    assert pd\n",
    "    assert np\n",
    "    assert regex\n",
    "    assert os\n",
    "    assert sys\n",
    "    \n",
    "    # user experiment inputs \n",
    "    assert EXPERIMENT\n",
    "    assert FILTERED_FILEPATH\n",
    "    assert OUTPUT_DIRECTORY\n",
    "    assert MIN_READS\n",
    "    \n",
    "    # user columns\n",
    "    assert SAMPLE\n",
    "    assert QTAG\n",
    "    assert BARCODE\n",
    "    assert READS\n",
    "    assert MCOUNTS\n",
    "    assert PERCENT_MCOUNTS\n",
    "    assert GROUPBY\n",
    "    \n",
    "\n",
    "# 2016-11-04 updated to include filter delete bool feature\n",
    "\"\"\"calculate_percent_molecs\n",
    "    calculates percent of mcounts of barcodes.\n",
    "    df: pd.DataFrame() \n",
    "    mcounts: str, optional, col to calculate percents, default MCOUNTS\n",
    "    percent_mcounts: str, col to assign values to, default PERCENT_MCOUNTS\n",
    "    filters: list, np.array, dict, columns and bool values to filter values\n",
    "    \n",
    "    Returns: \n",
    "        df with updated percent_mcounts values\n",
    "\"\"\"\n",
    "def calculate_percent_molecs(df, mcounts=MCOUNTS, percent_mcounts=PERCENT_MCOUNTS, filters=[]):\n",
    "    \"\"\"Updates percent molec counters for sample\"\"\"\n",
    "    \n",
    "    df.loc[:,percent_mcounts] = 0.\n",
    "    if len(filters) > 0:\n",
    "        var, val = filters[0]\n",
    "        cond = (df[var]==val)\n",
    "        i = 1\n",
    "        while i < len(filters):\n",
    "            var, val = filters[i]\n",
    "            cond = cond & (df[var]==val)\n",
    "            i+=1\n",
    "    else:\n",
    "        cond = ()\n",
    "    total = df.loc[cond, mcounts].values.sum() / 100.\n",
    "    df.loc[cond,percent_mcounts] = df.apply(lambda x: x[mcounts]/total, axis=1)\n",
    "    df.sort_values(by=[percent_mcounts,mcounts, BARCODE], \n",
    "                   ascending=[0,0,1], inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_data(filtered_file, sample=SAMPLE, qtag=QTAG, \n",
    "              barcode=BARCODE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Loads filtered lib-ID-barcode data csv to dict of samples\"\"\"\n",
    "    columns = [sample, qtag, barcode, mcounts, reads]\n",
    "    # loads excel file (all tabs)\n",
    "    \n",
    "    csv = pd.read_csv(filtered_file)\n",
    "    # filter out null barcodes just in case (if custom user input)\n",
    "    csv = csv.loc[(csv[qtag]!='None') & (csv[barcode]!='None')]\n",
    "    csv = csv[columns]\n",
    "    csv[sample] = csv[sample].apply(lambda x: str(x))\n",
    "    # get percent molecs per sample, store as output dict entry \n",
    "    groups = csv.groupby(sample)\n",
    "    data = []\n",
    "    for i, group in csv.groupby(sample):\n",
    "        data.append((i,calculate_percent_molecs(group)))\n",
    "    return data\n",
    "\n",
    "\n",
    "def check_data(d, sample=SAMPLE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Check data for proper format, input values, and \n",
    "    converts into list-like object if necessary\n",
    "\n",
    "    d(list, np.array ,dict, or pd.DataFrame): input data\n",
    "    \n",
    "    Returns: data set as a list-like object, wherein\n",
    "        each item is a pair containing sample name (str) and \n",
    "        sample data (pd.DataFrame), in that order.\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "    # wrangle data to list of list-like pairs, as \"[idx, df]\"\n",
    "    if type(d) in [np.array, list] :\n",
    "        data_arr = d\n",
    "    elif type(d) == dict:\n",
    "        data_arr = d.items()\n",
    "    elif type(d) == pd.DataFrame :\n",
    "        data_arr = [(s,df) for s,df in d.groupby(sample)]\n",
    "    else:\n",
    "        print \"Input data is not in correct format. Please provide \\\n",
    "        list-like, dict, or pd.DataFrame object.\"\n",
    "    \n",
    "    # check input has correct values\n",
    "    try:\n",
    "        for a in data_arr:\n",
    "            assert len(a) == 2, \"incorrect item length\"\n",
    "            s, df = a\n",
    "            assert type(s) == str, 'sample name is not string type'\n",
    "            assert type(df) == pd.DataFrame, \"incorrect value type: must be pd.DataFrame\"\n",
    "            assert sample in df.columns, \"%s not in dataframe\"%sample\n",
    "            assert mcounts in df.columns, \"%s not in dataframe\"%mcounts\n",
    "            assert reads in df.columns, \"%s not in dataframe\"%reads\n",
    "    # if no \n",
    "    except IndexError as e:\n",
    "        print \"Item number of values is not 2.\\n\"\n",
    "        print \"IndexError. \",e.message\n",
    "        print a\n",
    "    except ValueError as e:\n",
    "        print \"Sample name could not be converted to float: %s\\n\"% type(item[i])\n",
    "        print \"ValueError. \",e.message\n",
    "        print a\n",
    "    except AssertionError as e:\n",
    "        print \"Assertion failed:\"\n",
    "        print e.message\n",
    "        print a\n",
    "    \n",
    "    return data_arr\n",
    "\n",
    "\"\"\"OLD THRESHOLD\"\"\"\n",
    "\n",
    "def threshold(group, reps_remaining, thresh_mcounts,\n",
    "             mcounts=MCOUNTS):\n",
    "    \"\"\"Thresholds barcodes of a given sample\n",
    "\n",
    "        group(pd.DataFrame): df containing library-ID-barcodes, \n",
    "            mcountsPF and percent_mcountsPF\n",
    "        reps_remaining(int): reps remaining from max number \n",
    "            input from user \n",
    "        thresh_val(float or int): initial threshold value (percent_mcountPF)\n",
    "            provided from previous recursion or user input\n",
    "        thresh_i(int): initial position of threshold value in \n",
    "            percent_mcountsPF list, ranging 0,len(group)\n",
    "\n",
    "        Returns: \n",
    "            None, if thresholding fails;\n",
    "            passed(pd.DataFrame), if thresholding successful; or\n",
    "            self, otherwise, with updated threshold values and \n",
    "                group df.\n",
    "    \"\"\"\n",
    "    # max out reps\n",
    "    if reps_remaining <= 0:\n",
    "        print 'Maxed out reps. Skipping sample.'\n",
    "    # no barcodes passed threshold \n",
    "    elif len(group) == 0:\n",
    "        print \"No barcodes passed threshold. Skipping sample.\"\n",
    "    else:\n",
    "        # calculate new threshold \n",
    "        group.sort_values(by=mcounts, ascending=False, inplace=True)\n",
    "        new_thresh_mcounts = calculate_threshold(group)\n",
    "        # if reached steady state\n",
    "        if new_thresh_mcounts == thresh_mcounts:\n",
    "            passed = group.loc[(group['passed']==True)\n",
    "                              &(group['is_padding']==False)\n",
    "                              &(group[mcounts]>=thresh_mcounts)]\n",
    "            passed = calculate_percent_molecs(passed)\n",
    "#             passed = calculate_percent_molecs(group, \n",
    "#                         filters=[['passed',True],['is_padding',False]])\n",
    "            passed.reset_index(inplace=True,drop=True)\n",
    "            print reps_remaining, len(passed.loc[passed['passed']==True])\n",
    "            sys.stdout.write('Thresholded.\\n')\n",
    "            return passed\n",
    "        # recursively clean and re-threshold\n",
    "        else:\n",
    "            # clean up group by eliminating one-offs\n",
    "            cleaned = eliminate_oneoffs(group,new_thresh_mcounts)\n",
    "            cleaned.reset_index(inplace=True,drop=True)\n",
    "            print reps_remaining, len(cleaned.loc[cleaned['passed']==True])\n",
    "            # recurse with cleaned df and new threshold values\n",
    "            return threshold(cleaned, reps_remaining-1, new_thresh_mcounts, \n",
    "                             mcounts=mcounts)\n",
    "        \n",
    "    # if thresholding failed, return None\n",
    "    sys.stdout.write('Skipped.\\n')\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# STEP 2: CALCULATE THRESHOLD VALUE via. CONCAVITY\n",
    "\n",
    "\n",
    "def calculate_threshold(y, by='passed', mcounts=MCOUNTS):\n",
    "    \"\"\"Calculates threshold of series with modified concavity approach\n",
    "\n",
    "        y(np.array or list): list or list-like object of \n",
    "            values as floats or ints\n",
    "\n",
    "        Returns index of inflection point in array, \n",
    "            i.e. threshold position.\n",
    "    \"\"\"\n",
    "    def rolling_window(arr):\n",
    "        \"\"\"Constructs list of overlapping subarray ranges of size 2\"\"\"\n",
    "        shape = arr.shape[:-1] + (arr.shape[-1]-1, 2)\n",
    "        strides = arr.strides + (arr.strides[-1],)\n",
    "        windows = np.lib.stride_tricks.as_strided(arr, \n",
    "                              shape=shape, strides=strides)\n",
    "        return windows\n",
    "    def first_d_gen(windows):\n",
    "        \"\"\"Generates first derivative of windows as relative difference\"\"\"\n",
    "        for w in windows:\n",
    "            # amended 2016-10-12: normalize by y midpoint instead of second point to \n",
    "            # better represent the count magnitude of segment\n",
    "            yield float(w[1]-w[0])/(w[0]+w[1])*2\n",
    "    def second_d_gen(windows):\n",
    "        \"\"\"Generates second derivative of windows\"\"\"\n",
    "        for w in windows:\n",
    "            yield w[1]-w[0]         \n",
    "    if type(y) in [np.ndarray, list]:\n",
    "        x_temp = np.array([])\n",
    "        y_temp = np.array(y)\n",
    "    else:\n",
    "        y = pd.DataFrame(y)\n",
    "        sortby, cond = [mcounts], (y[mcounts]>0)\n",
    "        if by in y.columns:\n",
    "            sortby, cond = [by]+sortby, cond&(y[by]==True) \n",
    "        passed = y.loc[cond].sort_values(by=sortby,ascending=False)[mcounts]\n",
    "        x_temp = passed.index.values\n",
    "        y_temp = passed.values\n",
    "\n",
    "    y_temp = np.sort(np.array(y_temp))[::-1]\n",
    "    # left and right padding to cover all array vals in derivations\n",
    "    yarray = np.concatenate([ [y_temp[0]], y_temp, [1] ])\n",
    "    # calculates first derivative\n",
    "    first_windows = rolling_window(yarray)\n",
    "    first_derivs = np.fromiter(first_d_gen(first_windows), np.float\n",
    "                               , count=len(first_windows))\n",
    "    # calculates second derivative\n",
    "    second_windows = rolling_window(first_derivs)\n",
    "    second_derivs = np.fromiter(second_d_gen(second_windows), np.float\n",
    "                                , count=len(second_windows))\n",
    "    # gets index or position value of inflection point (curves down ), adjust by adding 1\n",
    "    # for second deriv\n",
    "    thresh_i = min(np.argmin(second_derivs)+1, len(y_temp)-1)\n",
    "    thresh_v = y_temp[thresh_i]\n",
    "\n",
    "    return thresh_v\n",
    "\n",
    "def eliminate_oneoffs(g, thresh_val, pad=True,\n",
    "                      qtag=QTAG, barcode=BARCODE, passed='passed',\n",
    "                      barcode_error = 'barcode_error',\n",
    "                      qtag_error = 'qtag_error',\n",
    "                      mcounts=MCOUNTS):\n",
    "    \"\"\"Eliminate barcodes that are one position off from a more-abundant barcode\n",
    "        group(pd.DataFrame): df containing qtag, barcode, and percent_mcounts columns\n",
    "        thresh_val(float): threshold value to select high abundant barcodes\n",
    "            to iterate through as 'major' ones\n",
    "        pad(bool): if True, adds a right pad so last non-eliminated value \n",
    "            can be analyzed in by the threshold() function. Default True.\n",
    "        qtag, barcode, percent_mcounts, mcounts (str): column names for the corresponding\n",
    "            argument. Defaults are global vars QTAG, BARCODE, PERCENT_MCOUNTS, MCOUNTS.\n",
    "\n",
    "        Returns: table of barcodes that passed elimination\n",
    "        \n",
    "        For regex package info, see https://pypi.python.org/pypi/regex/\n",
    "    \"\"\"\n",
    "    g.sort_values(by=mcounts, ascending=False, inplace=True)\n",
    "#     g.loc[g[mcounts] < thresh_val, 'passed'] = False\n",
    "\n",
    "    filter_g = g.loc[(g['passed']==True)|(g['is_padding']==True)]\n",
    "    majors = filter_g.loc[(filter_g[mcounts])>thresh_val]\n",
    "    \n",
    "    # add capability to check other parameters, i.e. qtag\n",
    "    for maj_i, maj_r in majors.iterrows():\n",
    "        # if it has not yet been tested\n",
    "        if g.loc[maj_i,'passed'] == True:\n",
    "#             minors = filter_g.loc[filter_g[mcounts]<maj_r[mcounts]]\n",
    "\n",
    "            minors = filter_g.loc[filter_g[mcounts]<maj_r[mcounts]]\n",
    "\n",
    "            # for each 'minor' barcode aka. with fewer molecs, test if one-off from major\n",
    "            for min_i, min_r in minors.iterrows():\n",
    "                query = regex.search(\"(?P<barcode>%s){s<=1}\" \n",
    "                            % maj_r[barcode], min_r[barcode])\n",
    "                if query:\n",
    "                    g.loc[min_i,'barcode_error'] += 1 if sum(query.fuzzy_counts)>0 else 0\n",
    "                    g.loc[min_i,'qtag_error'] += 1 if min_r[qtag]!=maj_r[qtag] else 0\n",
    "                    g.loc[min_i,'passed'] = False\n",
    "#     # if requested, adds a right pad  \n",
    "#     # line added 2016-10-12: combine two conditions: ensure that \n",
    "#     # no null rows get added if all barcodes are accepted\n",
    "    g.loc[:,'is_padding'] = False\n",
    "    if pad==True and len(g) != len(g['passed']==False):\n",
    "        pad_i = g.loc[(g['passed']==False) & (g[mcounts]<thresh_val)\n",
    "                      ,mcounts].idxmax()\n",
    "        \n",
    "        g.loc[pad_i,'is_padding'] = True\n",
    "    return g\n",
    "            \n",
    "\n",
    "def run_threshold(d, sample=SAMPLE, qtag=QTAG, barcode=BARCODE, \n",
    "                  mcounts=MCOUNTS, reads=READS, percent_mcounts=PERCENT_MCOUNTS,\n",
    "                  min_reads=MIN_READS, min_mcount=50):\n",
    "    \"\"\"Run threshold algorithm for each sample in dataset\n",
    "\n",
    "        d(np.array, list, dict, or pd.DataFrame): dataset for all samples\n",
    "        sample, qtag, barcode, mcounts, reads, percent_mcounts(str): columns in df for \n",
    "            corresponding vals. Defaults are global vars SAMPLE, QTAG, BARCODE, MCOUNTS, \n",
    "            READS, PERCENT_MCOUNTS.\n",
    "        min_reads(int): minimum number of reads for a library-ID-barcode as an \n",
    "            absolute baseline (that which any barcode below is highly likely to be \n",
    "            false.) Default is global var MIN_READS.\n",
    "        min_mcount(int): minimum number of molecs for library-ID-barcode as an\n",
    "            absolute baseline. Default is 50.\n",
    "\n",
    "        Note: min_reads and min_mcount are applied to increase performance.\n",
    "\n",
    "        Returns: \n",
    "            pd.DataFrame, if successful, of 'true' (passed) library-ID-barcodes \n",
    "                for all samples\n",
    "            None, if no samples had passing library-ID-barcodes.\n",
    "    \"\"\"\n",
    "    passed = []\n",
    "    counter = 1\n",
    "    # checks and formats data (d) to list-like obj of pairs\n",
    "    data_arr = check_data(d, sample=sample, mcounts=mcounts, reads=reads)\n",
    "    # run for each (sample, df) in dataset \n",
    "    for s, group in data_arr:\n",
    "        sys.stdout.write(\"\\nSample %d of %d (%s): \"%(counter,len(data_arr),s))\n",
    "        # select valid data meeting absolute baseline \n",
    "        g = group.loc[(group[qtag] != 'None') & (group[barcode] != 'None') \n",
    "                          & (group[mcounts] > min_mcount)\n",
    "                          & (group[reads] > min_reads)]\n",
    "        if len(g)>0:\n",
    "        \n",
    "            g.loc[:,'passed'] = True\n",
    "            g.loc[:,'qtag_error'] = False\n",
    "            g.loc[:,'barcode_error'] = False\n",
    "            g.loc[:,'is_padding'] = False\n",
    "            result = threshold(g, 20, -1)\n",
    "            passed.append(result)\n",
    "        sys.stdout.flush()\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    # if we do have data (i.e. some barcodes that passed in the samples)\n",
    "    if len(passed) > 0:\n",
    "        # concat all df together\n",
    "        passeddf = pd.concat(passed)\n",
    "        passeddf.sort_values(by=[sample,percent_mcounts]\n",
    "                             ,ascending=[True, False]\n",
    "                             ,inplace=True)\n",
    "        passeddf.reset_index(inplace=True,drop=True)\n",
    "        return passeddf\n",
    "    else:\n",
    "        print \"No samples were successfully thresholded.\"\n",
    "    return \n",
    "\n",
    "### SCRIPT TO SAVE DATA TO CSVs\n",
    "\n",
    "def save_data(filtered,passed, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT):\n",
    "    \n",
    "    # Save passed dataframe\n",
    "    passed.to_csv('%s/threshold-%s-passed.csv'%(output_directory,experiment), index=False)\n",
    "    # count and save results\n",
    "    counts = count_sample_barcodes(passed)\n",
    "    counts.to_csv('%s/threshold-%s-counts.csv'%(output_directory,experiment), index=False)\n",
    "    # merge passed and filtered data and save\n",
    "    fc_temp = pd.concat([d[1] for d in filtered])\n",
    "    filtered_concat = apply_passed_data(fc_temp, passed)\n",
    "    filtered_concat.to_csv('%s/threshold-%s-merged.csv'%(output_directory,experiment), index=False)\n",
    "\n",
    "def count_sample_barcodes(df, groupby=SAMPLE, barcode=BARCODE, sample=SAMPLE, qtag=QTAG\n",
    "                      , percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Counts passed barcodes per sample and saves as csv\n",
    "    \n",
    "        df(pd.DataFrame): input dataframe containing passed \n",
    "            barcodes of all samples\n",
    "        groupby(str or list-like): columns to group samples by\n",
    "    \"\"\"\n",
    "    agg = df.groupby(groupby).agg(len)\n",
    "    counts = agg[agg.columns[0]]\n",
    "    counts.name = 'count'\n",
    "    counts = pd.DataFrame(counts)\n",
    "    counts.reset_index(inplace=True)\n",
    "    return counts\n",
    "\n",
    "\n",
    "\n",
    "def apply_passed_data(filtered, passeddf, sample=SAMPLE, qtag=QTAG\n",
    "                      , barcode=BARCODE, percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Cross reference passed barcodes with raw filtered data\n",
    "        filtered(pd.DataFrame): raw filtered data as dataframe for all samples\n",
    "        passed(pd.DataFrame): data passed threshold (output of run_threshold)\n",
    "        sample,qtag,barcode,percent_mcounts(str): names corresponding to df columns.\n",
    "            Defaults are SAMPLE,QTAG,BARCODE,PERCENT_MCOUNTS.\n",
    "\n",
    "        Returns:\n",
    "            filtered(pd.DataFrame) updated with 'passed_threshold' and \n",
    "            percent_mcounts columns\n",
    "    \"\"\"\n",
    "    def cross_ref_passed(row):\n",
    "        key = (row[sample],row[qtag],row[barcode])\n",
    "        if key in passed_indexed.index:\n",
    "            row.loc[:,percent_mcounts+'_thresholded'] = passed_indexed.loc[key,percent_mcounts]\n",
    "            row.loc[:,'passed_threshold'] = True\n",
    "        return row\n",
    "\n",
    "    passed_indexed = passeddf.set_index([sample,qtag,barcode])\n",
    "    filtered.rename(columns={percent_mcounts:percent_mcounts+'_filtered'})\n",
    "    filtered.loc[:,'passed_threshold'] = False\n",
    "    filtered.loc[:,percent_mcounts+'_thresholded'] = 0\n",
    "    filtered = filtered.apply(cross_ref_passed, axis=1)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "# EXECUTE SCRIPT BELOW\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Check all inputs exist and are valid\n",
    "    check_inputs()\n",
    "    # Runs data loading in script\n",
    "    filtered = load_data(FILTERED_FILEPATH)\n",
    "    # Run thresholding of all samples in dataset\n",
    "    passeddf = run_threshold(filtered)\n",
    "#     save_data(filtered, passeddf, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT)\n",
    "# VL ones got messed up in read_fastq for some reason\n",
    "\n",
    "    fconcat = pd.concat([d[1] for d in filtered if d[0][:2]!=\"VL\" ])\n",
    "\n",
    "\n",
    "    merged = fconcat.merge(passeddf, \n",
    "                  on=['idx','qtag','barcode','mcountsPF','readsPF'], \n",
    "                           how='outer')\n",
    "    merged.drop(['percent_mcountsPF_x','is_padding'],axis=1, inplace=True)\n",
    "    merged.rename(columns={'percent_mcountsPF_y':\"percent_mcountsPF\"}, inplace=True)\n",
    "    merged = merged.fillna(value={'passed':False,'qtag_error':False,'barcode_error':False,\n",
    "                        'percent_mcountsPF':0.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "passeddf.to_csv(\"%s/passed-%s.csv\"%(OUTPUT_DIRECTORY,EXPERIMENT))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plots scatter\n",
    "for idx, group in filtered_concat.groupby('idx'):\n",
    "    g = group.sort_values(by='mcounts_PF',ascending=False)\n",
    "    counts = g.mcounts_PF.values\n",
    "    itypes = g.qb_type.values\n",
    "\n",
    "    f, ax = plt.subplots(1)\n",
    "    # 0 == passed\n",
    "    # 1 == fail (not mismatch)\n",
    "    # 2 == fail (mismatch)\n",
    "    for i in [0,1,2]:\n",
    "        x = []\n",
    "        y = []\n",
    "        j = 0\n",
    "        typecount = 0\n",
    "        while j < len(counts):\n",
    "            if itypes[j]==i and counts[j]>1:\n",
    "                x.append(j)\n",
    "                y.append(counts[j])\n",
    "                typecount += 1\n",
    "            j+=1\n",
    "        label = \"%s: %d\"%(labels[i],typecount)\n",
    "        alpha = 1\n",
    "        ax.bar(x, y, fill=ctypes[i], alpha=alpha, label=label,\n",
    "                  lw=0)\n",
    "        ax.scatter(x, y, color=ctypes[i], alpha=alpha, label=label,\n",
    "                  marker='.', lw=2)\n",
    "\n",
    "    thresh =max(np.where(itypes==0)[0]) \n",
    "    ax.plot([thresh,thresh],[1,max(counts)], color = ctypes[0], label='%d QB > threshold'%len(np.where(itypes==0)[0]))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim(0)\n",
    "    ax.legend()\n",
    "    ax.set_title(idx)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "passeddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itypes = {\n",
    "    (True,False,False):'passed', #passed\n",
    "    (False,True,False):'qtag mismatch', #qtag error\n",
    "    (False,False,True):'barcode oneoff', #barcode error\n",
    "    (False,False,False):'other error' #not one-off\n",
    "}\n",
    "\n",
    "for itype in itypes:\n",
    "    keys = ['passed','qtag_error','barcode_error']\n",
    "    ca = [(merged[k]==v) for k,v in zip(keys,itype)]\n",
    "    cond = ca[0]&ca[1]&ca[2]\n",
    "    merged.loc[(cond),'itype'] = itypes[itype]\n",
    "    \n",
    "ctypes = {\n",
    "    'passed':'#11BF08',\n",
    "    'barcode oneoff': '#DE092B',\n",
    "    'qtag mismatch':'#EBA709',\n",
    "    'other error':'#2A52D5'\n",
    "}\n",
    "itype_order = [\n",
    "    'passed',\n",
    "    'other error',\n",
    "    'barcode oneoff',\n",
    "    'qtag mismatch'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plots scatter\n",
    "plottype = 'scatter'\n",
    "mcounts=MCOUNTS\n",
    "counter = 0\n",
    "for idx, group in merged.groupby('idx'):\n",
    "    if idx[:2]=='NH':\n",
    "        gslice = group.sort_values(by=mcounts,ascending=False)\n",
    "        gslice = gslice.loc[gslice[mcounts]>1]\n",
    "        counts = gslice[mcounts].values\n",
    "        itypes = gslice.itype.values\n",
    "        it_present= np.unique(itypes)\n",
    "        \n",
    "        f, ax = plt.subplots(1)\n",
    "        for itype in itype_order:\n",
    "            if itype in it_present:\n",
    "                x = np.where(itypes==itype)[0]\n",
    "                y = counts[x]\n",
    "                label = \"%s: %d\"%(itype,len(x))\n",
    "                color = ctypes[itype]\n",
    "                alpha = 0.5 if itype in ['passed','other error'] else 1\n",
    "                edgecolor=color\n",
    "                lw = 1.5\n",
    "                s = 250 if itype in ['barcode oneoff','qtag mismatch'] else 8\n",
    "                marker = \"|\" if itype in ['barcode oneoff','qtag mismatch'] else \"o\"\n",
    "                    \n",
    "                if plottype == 'scatter':\n",
    "                    ax.scatter(x+1, y, color=color, edgecolors=edgecolor,\n",
    "                            alpha=alpha, label=label, \n",
    "                            marker=marker, lw=lw, s=s)\n",
    "                    \n",
    "                else:\n",
    "                    ax.bar(x, y, color=color, alpha=alpha, \n",
    "                           label=label, lw=0, width=1 )\n",
    "        \n",
    "        thresh_line =np.max(np.where(itypes=='passed')[0])+1\n",
    "        ax.plot([thresh_line,thresh_line],[1,max(counts)], \n",
    "                color = 'black', alpha = 1, ls = '--',\n",
    "                label='%d QB > threshold'%thresh_line)\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(0)\n",
    "        ax.legend()\n",
    "        ax.set_title(idx)\n",
    "#         break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#####  Color Palette by Paletton.com\n",
    "#####  Palette URL: http://paletton.com/#uid=c3P112O5x0kuKtzjHyVsYK-v+n-Cvj1\n",
    "\n",
    "1.  BLUE    other error\n",
    "2.  GREEN   passed\n",
    "3.  RED     barcode oneoff\n",
    "4.  YELLOW  qtag mismatch\n",
    "\n",
    "*** Primary color:\n",
    "\n",
    "   shade 0 = #18379F = rgb( 24, 55,159) = rgba( 24, 55,159,1) = rgb0(0.094,0.216,0.624)\n",
    "   shade 1 = #5269B4 = rgb( 82,105,180) = rgba( 82,105,180,1) = rgb0(0.322,0.412,0.706)\n",
    "   >>>>shade 2 = #2A52D5 = rgb( 42, 82,213) = rgba( 42, 82,213,1) = rgb0(0.165,0.322,0.835)<<<<\n",
    "   shade 3 = #0F297F = rgb( 15, 41,127) = rgba( 15, 41,127,1) = rgb0(0.059,0.161,0.498)\n",
    "   shade 4 = #091F67 = rgb(  9, 31,103) = rgba(  9, 31,103,1) = rgb0(0.035,0.122,0.404)\n",
    "\n",
    "*** Secondary color (1):\n",
    "\n",
    "   shade 0 = #11BF08 = rgb( 17,191,  8) = rgba( 17,191,  8,1) = rgb0(0.067,0.749,0.031)\n",
    "   shade 1 = #58D351 = rgb( 88,211, 81) = rgba( 88,211, 81,1) = rgb0(0.345,0.827,0.318)\n",
    "   shade 2 = #20E616 = rgb( 32,230, 22) = rgba( 32,230, 22,1) = rgb0(0.125,0.902,0.086)\n",
    "   shade 3 = #089800 = rgb(  8,152,  0) = rgba(  8,152,  0,1) = rgb0(0.031,0.596,0)\n",
    "   shade 4 = #067B00 = rgb(  6,123,  0) = rgba(  6,123,  0,1) = rgb0(0.024,0.482,0)\n",
    "\n",
    "*** Secondary color (2):\n",
    "\n",
    "   shade 0 = #DE092B = rgb(222,  9, 43) = rgba(222,  9, 43,1) = rgb0(0.871,0.035,0.169)\n",
    "   shade 1 = #F25D75 = rgb(242, 93,117) = rgba(242, 93,117,1) = rgb0(0.949,0.365,0.459)\n",
    "   shade 2 = #F8183B = rgb(248, 24, 59) = rgba(248, 24, 59,1) = rgb0(0.973,0.094,0.231)\n",
    "   shade 3 = #B1001C = rgb(177,  0, 28) = rgba(177,  0, 28,1) = rgb0(0.694,0,0.11)\n",
    "   shade 4 = #8F0017 = rgb(143,  0, 23) = rgba(143,  0, 23,1) = rgb0(0.561,0,0.09)\n",
    "\n",
    "*** Complement color:\n",
    "\n",
    "   shade 0 = #EBA709 = rgb(235,167,  9) = rgba(235,167,  9,1) = rgb0(0.922,0.655,0.035)\n",
    "   shade 1 = #FFCF62 = rgb(255,207, 98) = rgba(255,207, 98,1) = rgb0(1,0.812,0.384)\n",
    "   shade 2 = #FFB918 = rgb(255,185, 24) = rgba(255,185, 24,1) = rgb0(1,0.725,0.094)\n",
    "   shade 3 = #BC8300 = rgb(188,131,  0) = rgba(188,131,  0,1) = rgb0(0.737,0.514,0)\n",
    "   shade 4 = #986900 = rgb(152,105,  0) = rgba(152,105,  0,1) = rgb0(0.596,0.412,0)\n",
    "\n",
    "\n",
    "#####  Generated by Paletton.com (c) 2002-2014"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
