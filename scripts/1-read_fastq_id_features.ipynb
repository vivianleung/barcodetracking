{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2838a5bb-9884-4371-9764-38d8903d3804"
   },
   "outputs": [],
   "source": [
    "\"\"\"Step 1: Read .FASTQ.gz files and ID features\n",
    "\n",
    "Updated 2 September 2016\n",
    "(Ready to go)\n",
    "Script uses sample data from \"../data/sample_data\"\n",
    "Sarah Fortune & JoAnn Flynn labs (VWL)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import sqlalchemy as sqla\n",
    "import types\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Experiment name to name output files\"\"\"\n",
<<<<<<< HEAD
    "EXPERIMENT = \"sample\"\n",
=======
    "EXPERIMENT = \"sample2\"\n",
    "\n",
    "\"\"\"Directory path(s) to input data\"\"\"\n",
    "INPUT_DIRECTORIES = [\"../data/sample_data\"]\n",
    "EXPERIMENT = \"mouse_sample\"\n",
>>>>>>> 837ac15c3471149d4c6db5b22234e31ff31ffa8d
    "\n",
    "\"\"\"Directory path(s) to input data\"\"\"\n",
    "INPUT_DIRECTORIES = [\"../data/sample_data\"]\n",
    "\n",
    "\"\"\"Directory path to save output\"\"\"\n",
    "OUTPUT_DIR = \"../output\"\n",
    "\n",
    "\"\"\"File path for qtag reference csv.\n",
    "    csv should have two columns, ordered [qtag id, sequence]\n",
    "\"\"\"\n",
    "QTAG_CSV = \"../helpers/qtag_ref.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESETS AND SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Required modules; checked by check_input()\"\"\"\n",
    "required_modules = [\n",
    "    np, pd, regex\n",
    "    , gzip, sqla\n",
    "    , os, sys, types\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "b6cf4954-61ba-4767-ac1b-d2059ac5fa68"
   },
   "outputs": [],
   "source": [
    "\"\"\"Motifs used to search for features\n",
    "  \n",
    "Motifs are strings with constant \"handles\" \n",
    "    and variable barcode sequences to capture in parentheses \n",
    "\n",
    "BARCODE_MOTIF(str) for barcode\n",
    "MCOUNT_MOTIF(str) for molecular counter\n",
    "INDEX_MOTIF(str) for .fastq.gz-like naming format \n",
    "    used to parse index names\n",
    "  \n",
    "\"\"\"\n",
    "BARCODE_MOTIF = \"CGA([ACTG]{3})C([ACTG]{4})AATTCGATGG\"\n",
    "MCOUNT_MOTIF = \"C([ACTG]{3})C([ACTG]{3})C([ACTG]{3})GCGCAACGCG\"\n",
    "INDEX_MOTIF = \"(.+)_S\\d{1,3}_L\\d{3}_R(\\d)_\\d{3}\\.fastq\\.gz\"\n",
    "# ASSERT USER INPUTS ARE VALID TYPES, EXIST (for paths), AND ARE NON-NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_modules():\n",
    "    try:\n",
    "        for mod in required_modules:\n",
    "            assert mod\n",
    "            assert type(mod)==types.ModuleType, mod.__name__+\" is not a module.\"\n",
    "\n",
    "    except (NameError, AssertionError) as e:\n",
    "        print e\n",
    "        print \"Please ensure the module has been imported and named correctly \\\n",
    "    and has not been redefined.\"\n",
    "\n",
    "    else:\n",
    "        print \"All modules have been imported successfully.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4d874ed7-56d5-4e0e-8182-eea97fe3a46b"
   },
   "outputs": [],
   "source": [
    "class Index(object):\n",
    "    \n",
    "    \"\"\"class Index(idx,reads,rexs)\n",
    "    \n",
    "    contains tallies from each pair of raw index reads files\n",
    "    \n",
    "    idx(str): index name\n",
    "    reads(list): list of file paths for fwd and rev reads, \n",
    "        parsed as file0, file1\n",
    "    rexs(dict): regex objects to find \n",
    "    \n",
    "    Constructs:\n",
    "    tname(str): index name with only alphanumeric characters for db table\n",
    "    \n",
    "    Returns: Index(obj)\n",
    "    \"\"\"\n",
    "    def __init__(self, idx, reads, rexs):\n",
    "        \"\"\" init_search(self)\n",
    "    \n",
    "        Opens raw compressed files and initializes iterreads search. \n",
    "        Returns qbm keyed dict with list of scores as values.\n",
    "        \"\"\"\n",
    "        self.idx = idx\n",
    "        self.file0, self.file1 = reads[:2]\n",
    "        self.tname = regex.sub('[^0-9a-zA-Z]+',\"\",idx)\n",
    "        self.rexs = rexs  \n",
    "        \n",
    "    def search_index(self):\n",
    "        # open raw .fastq.gz (compressed) files\n",
    "        try:\n",
    "            read0 = gzip.open(self.file0)\n",
    "            read1 = gzip.open(self.file1)\n",
    "        except Exception, e:\n",
    "            print \"Cannot open read files for %s.\\nAborting with Exception: %s\"%(self.idx,e)\n",
    "        else:\n",
    "            # init file reading\n",
    "            self.qbm_dict = self.iterreads(read0, read1)\n",
    "            return self\n",
    "\n",
    "    def iterreads(self, read0, read1):\n",
    "        \"\"\" iterreads(self, read0, read1)\n",
    "    \n",
    "        Reads through opened file pairs and records feature search results \n",
    "        \n",
    "        read0(file): opened compressed file for forward read\n",
    "        read1(file): opened compressed file for reverse read\n",
    "        \n",
    "        Returns dictionary of counts with keys as feature sequences (as tuple)\n",
    "        and list of paired base quality scores of barcodes and molecular counters\n",
    "        for each read. Function returns counts to init_search().\n",
    "        \"\"\"\n",
    "        # init output dict and line counter\n",
    "        line = 0\n",
    "        counts = {}\n",
    "        # in chunk, first tuple will contain fwd and rev read sequences,\n",
    "        # and second tuple with contain base QS for relevant \n",
    "        # (barcode, molecular counter) features\n",
    "        chunk = [(),()]\n",
    "        # iterating through paired read files\n",
    "        for r0, r1 in zip(read0, read1):\n",
    "            # if line contains read sequences, save to chunk\n",
    "            if line == 1:\n",
    "                chunk[0] = (r0, r1)\n",
    "            # if line contains base QS, save to chunk and search the reads\n",
    "            elif line == 3:\n",
    "                chunk[1] = (r0, r1)\n",
    "                key, scores = self.search_read(chunk)\n",
    "                # from search_reads, save with key as feature seqs as tuple, and \n",
    "                # value as tuple of base QS for barcode and molecular counter features\n",
    "                counts.setdefault(key,[])\n",
    "                counts[key].append(scores)\n",
    "                # line set to -2 to account for (a) += 1 at end of loop, and\n",
    "                # (b) to read and ignore the fourth row of the read set\n",
    "                # so that new read set will begin at 0.\n",
    "                line = -1 \n",
    "            line += 1\n",
    "        return counts\n",
    "\n",
    "    def search_read(self, chunk):\n",
    "        \"\"\" search_read(self,chunk)\n",
    "        \n",
    "        Given forward and reverse sequences and base QS for\n",
    "        a read, search for features using regex motif objects.\n",
    "        \n",
    "        Returns key as tuple of feature sequences, and\n",
    "        values as the barcode and molecular counter base QS. \n",
    "        Function returns key and values to iterreads(self, read0,read1).\n",
    "        \"\"\"\n",
    "        # parses chunk values\n",
    "        seq0, seq1 = chunk[0]\n",
    "        qs0, qs1 = chunk[1]\n",
    "        # searches for features (q: qtag, b: barcode, m:molecular counter) \n",
    "        q = regex.search(self.rexs['q'],seq1)\n",
    "        b = regex.search(self.rexs['b'],seq0)\n",
    "        m = regex.search(self.rexs['m'],seq0)\n",
    "        \n",
    "        # set defaults for scores as 'None'\n",
    "        # 'None' is used as string to avoid using different types\n",
    "        # for non-null and null values (i.e. float v str)\n",
    "        qtag = \"None\"\n",
    "        barcode = 'None'\n",
    "        mcount = 'None'\n",
    "        bscore = \"\"\n",
    "        mscore = \"\"\n",
    "        \n",
    "#         this is also more verbose and ugly but again,\n",
    "#         to make code clearer i've written it like this\n",
    "        \n",
    "        \"\"\"get name of the captured group (i.e. qid) if match\n",
    "            if barcode and/or molecular counter are found, extract \n",
    "            the sequence parts (one per group separated by the constant handle)\n",
    "            and join to form one string, and get base QS for the relevant region\n",
    "            region includes the entire motif region to also check handles\n",
    "        \"\"\" \n",
    "        if q: \n",
    "            qtag = q.lastgroup\n",
    "        if b:\n",
    "            barcode = \"\".join(b.groups())\n",
    "            bscore = qs0[b.start():b.end()]\n",
    "        if m:\n",
    "            mcount = \"\".join(m.groups())\n",
    "            mscore = qs0[m.start():m.end()]\n",
    "        # construct key and spans tuples for handoff\n",
    "        key = (qtag,barcode,mcount)\n",
    "        scores = [bscore, mscore]\n",
    "        return key, scores \n",
    "            \n",
    "    def construct_qbm_keyed_df(self, delete_dict=False):\n",
    "        qbm = pd.DataFrame(self.qbm_dict.keys(), columns=['qtag','barcode','mcount'])\n",
    "        qbm = qbm.reindex(columns=np.concatenate([qbm.columns,['scores']]))\n",
    "        qbm.scores = qbm.apply(lambda x: self.qbm_dict[ (x.qtag,x.barcode,x.mcount) ], axis=1)\n",
    "        self.qbm = qbm\n",
    "        if delete_dict: \n",
    "            del self.qbm_dict\n",
    "        return self    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "focus": true,
    "id": "48089a19-a99b-4adc-b194-64ea9f91698a"
   },
   "outputs": [],
   "source": [
    "def load_qtags(qtag_csv,id_col=0,sequence_col=1):\n",
    "    \"\"\"Load_qtags parses csv,returns pd.DataFrame with qtag id and sequence\"\"\"\n",
    "    # load qtag csv into df\n",
    "    try:\n",
    "        qtag_df = pd.DataFrame.from_csv(qtag_csv)\n",
    "        qtag_df.reset_index(inplace=True)\n",
    "        df_cols = len(qtag_df.columns)\n",
    "        \n",
    "        assert df_cols == 2, \"Incorrect number of columns (%d cols) \"%(df_cols)\n",
    "        assert id_col != sequence_col, \"id_col and sequence_col have been assigned the same value \"\n",
    "        assert len(qtag_df) > 0, \"Empty dataframe \"\n",
    "    except IOError as e:\n",
    "        print \"Cannot find qtag file at %s. Aborting with Exception: %s.\"%(qtag_csv,e)\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    except AssertionError as e:\n",
    "        sys.stdout.write(e+\"\\n\")\n",
    "        sys.stdout.write(\"in qtag file at %s. Aborting with Exception: %s.\"%(qtag_csv,e))\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        qtag_df.columns = ['qid','seq']       \n",
    "    # format and wrangle df to output\n",
    "    qtag_df.qid = qtag_df.qid.apply(lambda x: 'q'+str(x))\n",
    "    qtag_df.seq = qtag_df.seq.str.upper()\n",
    "    qtag_df.set_index('seq',inplace=True)\n",
    "    return qtag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "611f307d-6729-4806-b8a6-f02b4377028a"
   },
   "outputs": [],
   "source": [
    "def make_rexs(barcode_motif, mcount_motif, qtags):\n",
    "    '''Construct regex motifs for features and return dict of names and regex objs'''\n",
    "    # construct qtag motif from qtag_df, with capture groups named by qid\n",
    "    qtag_motif = \"|\".join(['(?P<%s>%s)'%(q.qid,seq) for seq,q in qtags.iterrows()])\n",
    "    qtag_regex = regex.compile(qtag_motif, flags=regex.I)\n",
    "    # construct barcode and molecular counter motifs from user input\n",
    "    barcode_regex = regex.compile(barcode_motif, flags=regex.I)\n",
    "    mcount_regex = regex.compile(mcount_motif, flags=regex.I)\n",
    "    return {'q':qtag_regex,'b':barcode_regex,'m':mcount_regex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "683bb9e3-9a38-46bb-bb25-b03b0a6c1982"
   },
   "outputs": [],
   "source": [
    "def init_indexes(root, rexs):\n",
    "    '''Finds relevant files with index motif and returns dict of Index obj'''\n",
    "    indexes = {}\n",
    "    # checks that directory exists\n",
    "    if os.path.isdir(root):\n",
    "        for directory, sub, files in os.walk(root):\n",
    "            for f in files:\n",
    "                # check if file should be read (i.e. .fastq.gz)\n",
    "                term = regex.search(INDEX_MOTIF, f)\n",
    "                # if valid\n",
    "                if term and term[0]!='Undetermined':\n",
    "                    # get capture groups index name (idx), read num {0,1}\n",
    "                    idx, read = term.groups()\n",
    "                    read = int(read)\n",
    "                    # add file entry to output dict\n",
    "                    indexes.setdefault(idx, [\"\",\"\"])\n",
    "                    indexes[idx][int(read)-1] = directory+\"/\"+f\n",
    "    for idx in indexes:\n",
    "        indexes[idx] = Index(idx, indexes[idx], rexs)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "dce70a8f-af25-4d8a-bfca-b031ed28367e"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class Counts(object):\n",
    "    \"\"\" Counts object(self, idx, counts)\n",
    "\n",
    "    used to manipulate tallied data from Index\n",
    "    to get final, non-thresholded but filtered library-ID-barcode counts \n",
    "    \n",
    "    Requires:\n",
    "    idx(str):  index name\n",
    "    counts(dict): dict containing feature combinations (qtag-barcode-molecularcounter) \n",
    "        as keys, and list of base QS for barcode and/or molecular counter regions as values.\n",
    "        (counts dict is generated by Index object)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, idx):\n",
    "        \"\"\"init object with idx dict\"\"\"\n",
    "        self.idx = idx\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_readsPF(scores):\n",
    "        \"\"\"ID reads with min QS < 30 and returns number of readsPF\"\"\"\n",
    "        readsPF = 0\n",
    "        # base score chars that represent QS >= 30\n",
    "        pass_scores = \"[^\\?@ABCDEFGHI]\"\n",
    "        for readQS in scores:\n",
    "            # search for any chars that are not in the high-QS char set\n",
    "            qs_0 = regex.search(pass_scores,readQS[0])\n",
    "            qs_1 = regex.search(pass_scores,readQS[1])\n",
    "            # if both reads are good, add to PF count\n",
    "            if (not qs_0) and (not qs_1):\n",
    "                readsPF += 1\n",
    "        return readsPF\n",
    "\n",
    "    def filter_reads(self, qbm):\n",
    "        \"\"\"filter out reads by QS and drop empty data rows\"\"\"\n",
    "        # trim down df to include only valid reads (all features present)\n",
    "        # to cut down on processing time\n",
    "        qbm = qbm.loc[ (qbm.qtag!=\"None\") \n",
    "                      &(qbm.barcode!=\"None\")\n",
    "                      &(qbm.mcount!=\"None\")]\n",
    "        # counts reads PF and remove those with no reads PF (cut time)\n",
    "        qbm['readsPF'] = qbm.scores.apply(self.count_readsPF)\n",
    "        qbm = qbm.loc[qbm.readsPF > 0]\n",
    "        # count reads\n",
    "        qbm['reads'] = qbm.scores.apply(lambda x: len(x))\n",
    "        self.filtered_qbm = qbm\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def count_molecs(self): \n",
    "        \"\"\"from qbm data, counts number of molecular counters per qb\"\"\"\n",
    "        filtered_qbm = self.filtered_qbm\n",
    "        # count molecs(PF) and sum readsPF\n",
    "        pivoted = pd.pivot_table(filtered_qbm, index=['qtag','barcode'],values='readsPF', aggfunc=[sum, len])\n",
    "        # formatting\n",
    "        pivoted.rename(columns={'sum':'readsPF','len':'mcountsPF'},inplace=True)\n",
    "        pivoted.sort_values(by=['mcountsPF','readsPF'],ascending=False, inplace=True)\n",
    "        pivoted.reset_index(inplace=True)\n",
    "        pivoted['idx'] = self.idx\n",
    "        self.filtered_qb = pivoted\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "383b6306-4549-4a44-8ba5-07dac622b2b8"
   },
   "outputs": [],
   "source": [
    "if_exists = 'replace'\n",
    "output_csv_fpath = \"%s/filtered-%s.csv\"%(OUTPUT_DIR,EXPERIMENT)\n",
    "overwrite = True\n",
    "open_type = 'wb' if overwrite else 'ab'\n",
    "f = open(output_csv_fpath, open_type) \n",
    "\n",
    "def run(db_name=None):\n",
    "    # build required constants and regex\n",
    "    qtags = load_qtags(QTAG_CSV)\n",
    "    rexs = make_rexs(BARCODE_MOTIF, MCOUNT_MOTIF, qtags)\n",
    "    header = True    \n",
    "    # init sqldb\n",
    "    db_name = db_name.split(\".db\")[0] if db_name!=None else \"counts_%s\"%EXPERIMENT\n",
    "    db_filepath = 'sqlite:///%s/%s.db'%(OUTPUT_DIR, db_name)\n",
    "    engine = sqla.create_engine(db_filepath)\n",
    "    \n",
    "    # iterate through directories provided\n",
    "    for directory in INPUT_DIRECTORIES:\n",
    "        indexes = init_indexes(directory, rexs)\n",
    "        iterum = 1\n",
    "        # iterate through each index\n",
    "        for idx_name in indexes:\n",
    "            sys.stdout.write(\"\\nStarting %d of %d: %s\"%(iterum, len(indexes), idx_name))\n",
    "            sys.stdout.flush()\n",
    "            index = indexes[idx_name]\n",
    "            # search and ID features from raw files\n",
    "            index.search_index()\n",
    "            index.construct_qbm_keyed_df()\n",
    "            # count\n",
    "            sys.stdout.write(\"...\")\n",
    "            sys.stdout.flush()\n",
    "            # init Counts obj, QS filter reads and count molecs\n",
    "            counts = Counts(idx_name)\n",
    "            counts.filter_reads(index.qbm)\n",
    "            counts.count_molecs()\n",
    "            \n",
    "            # save to sqldb\n",
    "            conn = engine.connect()\n",
    "            counts.filtered_qb.to_sql(idx_name, engine, if_exists=if_exists)\n",
    "            conn.close()\n",
    "            # write to file\n",
    "            csv = counts.filtered_qb.to_csv(header=header)\n",
    "            header = False\n",
    "            f.write(csv)\n",
    "            f.flush()\n",
    "            iterum+=1\n",
    "            sys.stdout.write(\"Finished.\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    # clean up\n",
    "    engine.dispose()\n",
    "    f.close()\n",
    "    sys.stdout.write('\\nJob complete\\n')\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALL RUN BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules have been imported successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivianleung/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
>>>>>>> 837ac15c3471149d4c6db5b22234e31ff31ffa8d
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    check_modules()\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
