{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FIX THIS! (CALCULATE THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\"Experiment name to prepend output files\"\"\"\n",
    "# EXPERIMENT = \"18014_graphing-2\"\n",
    "# EXPERIMENT = 'filtered-sample-nh'\n",
    "# EXPERIMENT = 'filtered-ratios's\n",
    "EXPERIMENT = '18014'\n",
    "\n",
    "\"\"\"Directory path to input data \n",
    "    (filtered; output from '1-read_fastq_id_features)\n",
    "\"\"\"\n",
    "# FILTERED_FILEPATH = \"../output/filtered-sample-nh.csv\"\n",
    "# FILTERED_FILEPATH = \"../output/filtered-ratios.csv\"\n",
    "FILTERED_FILEPATH = \"../output/filtered-18014-valid.csv\"\n",
    "\n",
    "\n",
    "\"\"\"Directory path to save output\"\"\"\n",
    "OUTPUT_DIRECTORY = \"../output\"\n",
    "\n",
    "\"\"\"Minimum number of reads as a baseline. Used to simplify data processing.\"\"\"\n",
    "MIN_READS = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESETS AND SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# NEED TO FIGURE HOW TO RELOAD DEPENDENT FUNCTIONS\n",
    "UPON VALUE CHANGES\n",
    "Column names correspoinding to eponymous variables\"\"\"\n",
    "\n",
    "SAMPLE = 'idx'\n",
    "QTAG = 'qtag'\n",
    "BARCODE = 'barcode'\n",
    "READS = 'readsPF'\n",
    "MCOUNTS = 'mcountsPF'\n",
    "PERCENT_MCOUNTS = 'percent_%s'%MCOUNTS\n",
    "GROUPBY = ['idx']# for older versions/ formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_inputs():\n",
    "    \n",
    "    # modules\n",
    "    assert pd\n",
    "    assert np\n",
    "    assert regex\n",
    "    assert os\n",
    "    assert sys\n",
    "    \n",
    "    # user experiment inputs \n",
    "    assert EXPERIMENT\n",
    "    assert FILTERED_FILEPATH\n",
    "    assert OUTPUT_DIRECTORY\n",
    "    assert MIN_READS\n",
    "    \n",
    "    # user columns\n",
    "    assert SAMPLE\n",
    "    assert QTAG\n",
    "    assert BARCODE\n",
    "    assert READS\n",
    "    assert MCOUNTS\n",
    "    assert PERCENT_MCOUNTS\n",
    "    assert GROUPBY\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2016-11-04 updated to include filter delete bool feature\n",
    "\"\"\"calculate_percent_molecs\n",
    "    calculates percent of mcounts of barcodes.\n",
    "    df: pd.DataFrame() \n",
    "    mcounts: str, optional, col to calculate percents, default MCOUNTS\n",
    "    percent_mcounts: str, col to assign values to, default PERCENT_MCOUNTS\n",
    "    filters: list, np.array, dict, columns and bool values to filter values\n",
    "    \n",
    "    Returns: \n",
    "        df with updated percent_mcounts values\n",
    "\"\"\"\n",
    "def calculate_percent_molecs(df, mcounts=MCOUNTS, percent_mcounts=PERCENT_MCOUNTS, filters=[]):\n",
    "    \"\"\"Updates percent molec counters for sample\"\"\"\n",
    "    \n",
    "    df.loc[:,percent_mcounts] = 0.\n",
    "    if len(filters) > 0:\n",
    "        var, val = filters[0]\n",
    "        cond = (df[var]==val)\n",
    "        i = 1\n",
    "        while i < len(filters):\n",
    "            var, val = filters[i]\n",
    "            cond = cond & (df[var]==val)\n",
    "            i+=1\n",
    "    else:\n",
    "        cond = ()\n",
    "    total = df.loc[cond, mcounts].values.sum() / 100.\n",
    "    df.loc[cond,percent_mcounts] = df.apply(lambda x: x[mcounts]/total, axis=1)\n",
    "    df.sort_values(by=[percent_mcounts,mcounts, BARCODE], \n",
    "                   ascending=[0,0,1], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filtered_file, sample=SAMPLE, qtag=QTAG, \n",
    "              barcode=BARCODE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Loads filtered lib-ID-barcode data csv to dict of samples\"\"\"\n",
    "    columns = [sample, qtag, barcode, mcounts, reads]\n",
    "    # loads excel file (all tabs)\n",
    "    \n",
    "    csv = pd.read_csv(filtered_file)\n",
    "    # filter out null barcodes just in case (if custom user input)\n",
    "    csv = csv.loc[(csv[qtag]!='None') & (csv[barcode]!='None')]\n",
    "    csv = csv[columns]\n",
    "    csv[sample] = csv[sample].apply(lambda x: str(x))\n",
    "    # get percent molecs per sample, store as output dict entry \n",
    "    groups = csv.groupby(sample)\n",
    "    data = []\n",
    "    for i, group in csv.groupby(sample):\n",
    "        data.append((i,calculate_percent_molecs(group)))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_data(d, sample=SAMPLE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Check data for proper format, input values, and \n",
    "    converts into list-like object if necessary\n",
    "\n",
    "    d(list, np.array ,dict, or pd.DataFrame): input data\n",
    "    \n",
    "    Returns: data set as a list-like object, wherein\n",
    "        each item is a pair containing sample name (str) and \n",
    "        sample data (pd.DataFrame), in that order.\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "    # wrangle data to list of list-like pairs, as \"[idx, df]\"\n",
    "    if type(d) in [np.array, list] :\n",
    "        data_arr = d\n",
    "    elif type(d) == dict:\n",
    "        data_arr = d.items()\n",
    "    elif type(d) == pd.DataFrame :\n",
    "        data_arr = [(s,df) for s,df in d.groupby(sample)]\n",
    "    else:\n",
    "        print \"Input data is not in correct format. Please provide \\\n",
    "        list-like, dict, or pd.DataFrame object.\"\n",
    "    \n",
    "    # check input has correct values\n",
    "    try:\n",
    "        for a in data_arr:\n",
    "            assert len(a) == 2, \"incorrect item length\"\n",
    "            s, df = a\n",
    "            assert type(s) == str, 'sample name is not string type'\n",
    "            assert type(df) == pd.DataFrame, \"incorrect value type: must be pd.DataFrame\"\n",
    "            assert sample in df.columns, \"%s not in dataframe\"%sample\n",
    "            assert mcounts in df.columns, \"%s not in dataframe\"%mcounts\n",
    "            assert reads in df.columns, \"%s not in dataframe\"%reads\n",
    "    # if no \n",
    "    except IndexError as e:\n",
    "        print \"Item number of values is not 2.\\n\"\n",
    "        print \"IndexError. \",e.message\n",
    "        print a\n",
    "    except ValueError as e:\n",
    "        print \"Sample name could not be converted to float: %s\\n\"% type(item[i])\n",
    "        print \"ValueError. \",e.message\n",
    "        print a\n",
    "    except AssertionError as e:\n",
    "        print \"Assertion failed:\"\n",
    "        print e.message\n",
    "        print a\n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"OLD THRESHOLD\"\"\"\n",
    "\n",
    "def threshold(group, reps_remaining, thresh_mcounts,threshold_log,\n",
    "             mcounts=MCOUNTS):\n",
    "    \"\"\"Thresholds barcodes of a given sample\n",
    "\n",
    "        group(pd.DataFrame): df containing library-ID-barcodes, \n",
    "            mcountsPF and percent_mcountsPF\n",
    "        reps_remaining(int): reps remaining from max number \n",
    "            input from user \n",
    "        thresh_val(float or int): initial threshold value (percent_mcountPF)\n",
    "            provided from previous recursion or user input\n",
    "        thresh_i(int): initial position of threshold value in \n",
    "            percent_mcountsPF list, ranging 0,len(group)\n",
    "\n",
    "        Returns: \n",
    "            None, if thresholding fails;\n",
    "            passed(pd.DataFrame), if thresholding successful; or\n",
    "            self, otherwise, with updated threshold values and \n",
    "                group df.\n",
    "    \"\"\"\n",
    "    # max out reps\n",
    "    if reps_remaining <= 0:\n",
    "        print 'Maxed out reps. Skipping sample.'\n",
    "    # no barcodes passed threshold \n",
    "    elif len(group[group[mcounts]>1]) == 0:\n",
    "        print \"No barcodes passed threshold. Skipping sample.\"\n",
    "    else:\n",
    "        # calculate new threshold \n",
    "        group.sort_values(by=mcounts, ascending=False, inplace=True)\n",
    "        mcount_vals = group.loc[(group['passed']==True)|(group['is_padding']==True)][mcounts].values\n",
    "        new_thresh_mcounts = calculate_threshold(mcount_vals)\n",
    "        \n",
    "        # if reached steady state\n",
    "        if new_thresh_mcounts == thresh_mcounts:\n",
    "            group.loc[:,'passed'] = group.apply(lambda x: \n",
    "                True if x['passed']==True and x[mcounts]>thresh_mcounts \n",
    "                    else False, axis=1)\n",
    "            group.reset_index(inplace=True,drop=True)\n",
    "            print \"FINAL\", len(group.loc[group['passed']==True])\n",
    "            sys.stdout.write('Thresholded.\\n')\n",
    "            return group, threshold_log\n",
    "        # recursively clean and re-threshold\n",
    "        else:\n",
    "            # clean up group by eliminating one-offs\n",
    "            cleaned = eliminate_oneoffs(group,new_thresh_mcounts)\n",
    "            cleaned.reset_index(inplace=True,drop=True)\n",
    "            # recurse with cleaned df and new threshold values\n",
    "            return threshold(cleaned, reps_remaining-1, new_thresh_mcounts, threshold_log,\n",
    "                             mcounts=mcounts)\n",
    "        \n",
    "    # if thresholding failed, return None\n",
    "    sys.stdout.write('Skipped.\\n')\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STEP 2: CALCULATE THRESHOLD VALUE via. CONCAVITY\n",
    "\n",
    "\n",
    "def calculate_threshold(y, by='passed', mcounts=MCOUNTS):\n",
    "    \"\"\"Calculates threshold of series with modified concavity approach\n",
    "\n",
    "        y(np.array or list): list or list-like object of \n",
    "            values as floats or ints\n",
    "\n",
    "        Returns index of inflection point in array, \n",
    "            i.e. threshold position.\n",
    "    \"\"\"\n",
    "    def rolling_window(arr):\n",
    "        \"\"\"Constructs list of overlapping subarray ranges of size 2\"\"\"\n",
    "        shape = arr.shape[:-1] + (arr.shape[-1]-1, 2)\n",
    "        strides = arr.strides + (arr.strides[-1],)\n",
    "        windows = np.lib.stride_tricks.as_strided(arr, \n",
    "                              shape=shape, strides=strides)\n",
    "        return windows\n",
    "    def first_d_gen(windows):\n",
    "        \"\"\"Generates first derivative of windows as relative difference\"\"\"\n",
    "        for w in windows:\n",
    "            yield float((w[1]-w[0]))/(w[1])\n",
    "    def second_d_gen(windows):\n",
    "        \"\"\"Generates second derivative of windows\"\"\"\n",
    "        for w in windows:\n",
    "            yield (w[1]-w[0])\n",
    "            \n",
    "    if type(y) in [np.ndarray, list]:\n",
    "        x_temp = np.array([])\n",
    "        y_temp = np.array(y)\n",
    "    else:\n",
    "        y = pd.DataFrame(y)\n",
    "        sortby, cond = [mcounts], (y[mcounts]>0)\n",
    "        if by in y.columns:\n",
    "            sortby, cond = ['passed']+sortby, cond&(y['passed']==True) \n",
    "        passed = y.loc[cond].sort_values(by=sortby,ascending=False)[mcounts]\n",
    "        x_temp = passed.index.values\n",
    "        y_temp = passed.values\n",
    "    \n",
    "    \n",
    "    y_temp = np.sort(np.array(y_temp))[::-1]\n",
    "    # left and right padding to cover all array vals in derivations\n",
    "    suffix = [2]\n",
    "    y_temp = y_temp[y_temp>1]\n",
    "    yarray = np.log10(np.concatenate([ [y_temp[0]], y_temp, suffix]))\n",
    "    \n",
    "    # calculates first derivative\n",
    "    first_windows = rolling_window(yarray)\n",
    "    first_derivs = np.fromiter(first_d_gen(first_windows), np.float\n",
    "                               , count=len(first_windows))\n",
    "    \n",
    "    print first_derivs\n",
    "    zeroes = np.where(first_derivs==0)\n",
    "    cutoff = zeroes[1] if len(zeroes) > 1 else len(first_derivs)\n",
    "    print cutoff, first_derives[cutoff-1:cutoff+2]\n",
    "    first_derivs = first_derives[:cutoff]\n",
    "    \n",
    "    # calculates second derivative\n",
    "    second_windows = rolling_window(first_derivs[abs(first_derivs)<float('inf')])\n",
    "\n",
    "    second_derivs = np.fromiter(second_d_gen(second_windows), np.float\n",
    "                                , count=len(second_windows))\n",
    "    # gets index or position value of inflection point (curves down ), adjust by adding 1\n",
    "    second_idxs = np.where(abs(second_derivs)<float('inf'))\n",
    "    second_derivs = second_derivs[second_idxs]\n",
    "    print second_derivs\n",
    "    thresh_deriv_i = second_idxs[0][np.argmin(second_derivs)] + 1\n",
    "    thresh_i = min(thresh_deriv_i, len(yarray)-1)\n",
    "    thresh_v = 10**yarray[thresh_i]\n",
    "    return thresh_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eliminate_oneoffs(g, thresh_val, pad=True,\n",
    "                      qtag=QTAG, barcode=BARCODE, passed='passed',\n",
    "                      barcode_error = 'barcode_error',\n",
    "                      qtag_error = 'qtag_error',\n",
    "                      mcounts=MCOUNTS):\n",
    "    \"\"\"Eliminate barcodes that are one position off from a more-abundant barcode\n",
    "        group(pd.DataFrame): df containing qtag, barcode, and percent_mcounts columns\n",
    "        thresh_val(float): threshold value to select high abundant barcodes\n",
    "            to iterate through as 'major' ones\n",
    "        pad(bool): if True, adds a right pad so last non-eliminated value \n",
    "            can be analyzed in by the threshold() function. Default True.\n",
    "        qtag, barcode, percent_mcounts, mcounts (str): column names for the corresponding\n",
    "            argument. Defaults are global vars QTAG, BARCODE, PERCENT_MCOUNTS, MCOUNTS.\n",
    "\n",
    "        Returns: table of barcodes that passed elimination\n",
    "        \n",
    "        For regex package info, see https://pypi.python.org/pypi/regex/\n",
    "    \"\"\"\n",
    "    g.sort_values(by=mcounts, ascending=False, inplace=True)\n",
    "    g.loc[:,'is_padding'] = False\n",
    "    # add capability to check other parameters, i.e. qtag\n",
    "    for maj_i, maj_r in g.loc[(g['passed']==True)].iterrows():\n",
    "        # if it has not yet been tested\n",
    "        if g.loc[maj_i,'passed'] == True:\n",
    "            minors = g.loc[(g['passed']==True)&(g[mcounts]<maj_r[mcounts])]\n",
    "            # for each 'minor' barcode aka. with fewer molecs, test if one-off from major\n",
    "            for min_i, min_r in minors.iterrows():\n",
    "                query = regex.search(\"(%s){s<=1}\"% maj_r[barcode], min_r[barcode])\n",
    "                if query:\n",
    "                    g.loc[min_i,'passed'] = False\n",
    "                    g.loc[min_i,'barcode_error'] += 1 if sum(query.fuzzy_counts)>0 else 0\n",
    "                    g.loc[min_i,'qtag_error'] += 1 if min_r[qtag]!=maj_r[qtag] else 0\n",
    "\n",
    "                    \n",
    "    # i f requested, adds a right pad  \n",
    "    if pad==True and len(g) != len(g.loc[g['passed']==False]):\n",
    "        min_true_val = g.loc[(g['passed']==True),mcounts].values.min\n",
    "        pad_i_choices = [ g.loc[(g['passed']==False)&(g[mcounts]<tval),mcounts][:2].index.values \n",
    "                         for tval in [min_true_val,thresh_val] ]\n",
    "        pad_i = pad_i_choices[np.argmin([len(c) for c in pad_i_choices])]\n",
    "        for pi in pad_i:\n",
    "            g.loc[pi,'is_padding'] = True\n",
    "    return g\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_threshold(d, sample=SAMPLE, qtag=QTAG, barcode=BARCODE, \n",
    "                  mcounts=MCOUNTS, reads=READS, percent_mcounts=PERCENT_MCOUNTS,\n",
    "                  min_reads=MIN_READS, min_mcount=50):\n",
    "    \"\"\"Run threshold algorithm for each sample in dataset\n",
    "\n",
    "        d(np.array, list, dict, or pd.DataFrame): dataset for all samples\n",
    "        sample, qtag, barcode, mcounts, reads, percent_mcounts(str): columns in df for \n",
    "            corresponding vals. Defaults are global vars SAMPLE, QTAG, BARCODE, MCOUNTS, \n",
    "            READS, PERCENT_MCOUNTS.\n",
    "        min_reads(int): minimum number of reads for a library-ID-barcode as an \n",
    "            absolute baseline (that which any barcode below is highly likely to be \n",
    "            false.) Default is global var MIN_READS.\n",
    "        min_mcount(int): minimum number of molecs for library-ID-barcode as an\n",
    "            absolute baseline. Default is 50.\n",
    "\n",
    "        Note: min_reads and min_mcount are applied to increase performance.\n",
    "\n",
    "        Returns: \n",
    "            pd.DataFrame, if successful, of 'true' (passed) library-ID-barcodes \n",
    "                for all samples\n",
    "            None, if no samples had passing library-ID-barcodes.\n",
    "    \"\"\"\n",
    "    passed = []\n",
    "    all_threshold_logs = {}\n",
    "    counter = 1\n",
    "    # checks and formats data (d) to list-like obj of pairs\n",
    "    data_arr = check_data(d, sample=sample, mcounts=mcounts, reads=reads)\n",
    "    # run for each (sample, df) in dataset \n",
    "    for s, group in data_arr:\n",
    "        sys.stdout.write(\"\\n-------------\\nSample %d of %d (%s): \"%(counter,len(data_arr),s))\n",
    "        # select valid data meeting absolute baseline \n",
    "        g = group.loc[(group[qtag] != 'None') & (group[barcode] != 'None') ]\n",
    "#                           & (group[mcounts] > min_mcount)\n",
    "#                           & (group[reads] > min_reads)]\n",
    "        if len(g.loc[g[mcounts]>2])>0:\n",
    "            g.loc[:,'passed'] = True\n",
    "            g.loc[:,'qtag_error'] = False\n",
    "            g.loc[:,'barcode_error'] = False\n",
    "            g.loc[:,'is_padding'] = False\n",
    "            result, tlogs = threshold(g, 20, -1, [])\n",
    "            passed.append(result)\n",
    "            all_threshold_logs[s] = tlogs\n",
    "        sys.stdout.flush()\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    # if we do have data (i.e. some barcodes that passed in the samples)\n",
    "    if len(passed) > 0:\n",
    "        # concat all df together\n",
    "        passeddf = pd.concat(passed)\n",
    "        passeddf.sort_values(by=[sample,percent_mcounts]\n",
    "                             ,ascending=[True, False]\n",
    "                             ,inplace=True)\n",
    "        passeddf.reset_index(inplace=True,drop=True)\n",
    "        return passeddf, all_threshold_logs\n",
    "    else:\n",
    "        print \"No samples were successfully thresholded.\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRIPT TO SAVE DATA TO CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(filtered,passed, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT):\n",
    "    \n",
    "    # Save passed dataframe\n",
    "    passed.to_csv('%s/threshold-%s-passed.csv'%(output_directory,experiment), index=False)\n",
    "    # count and save results\n",
    "    counts = count_sample_barcodes(passed)\n",
    "    counts.to_csv('%s/threshold-%s-counts.csv'%(output_directory,experiment), index=False)\n",
    "    # merge passed and filtered data and save\n",
    "    fc_temp = pd.concat([d[1] for d in filtered])\n",
    "    filtered_concat = apply_passed_data(fc_temp, passed)\n",
    "    filtered_concat.to_csv('%s/threshold-%s-merged.csv'%(output_directory,experiment), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_sample_barcodes(df, groupby=SAMPLE, barcode=BARCODE, sample=SAMPLE, qtag=QTAG\n",
    "                      , percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Counts passed barcodes per sample and saves as csv\n",
    "    \n",
    "        df(pd.DataFrame): input dataframe containing passed \n",
    "            barcodes of all samples\n",
    "        groupby(str or list-like): columns to group samples by\n",
    "    \"\"\"\n",
    "    agg = df.groupby(groupby).agg(len)\n",
    "    counts = agg[agg.columns[0]]\n",
    "    counts.name = 'count'\n",
    "    counts = pd.DataFrame(counts)\n",
    "    counts.reset_index(inplace=True)\n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_passed_data(filtered, passeddf, sample=SAMPLE, qtag=QTAG\n",
    "                      , barcode=BARCODE, percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Cross reference passed barcodes with raw filtered data\n",
    "        filtered(pd.DataFrame): raw filtered data as dataframe for all samples\n",
    "        passed(pd.DataFrame): data passed threshold (output of run_threshold)\n",
    "        sample,qtag,barcode,percent_mcounts(str): names corresponding to df columns.\n",
    "            Defaults are SAMPLE,QTAG,BARCODE,PERCENT_MCOUNTS.\n",
    "\n",
    "        Returns:\n",
    "            filtered(pd.DataFrame) updated with 'passed_threshold' and \n",
    "            percent_mcounts columns\n",
    "    \"\"\"\n",
    "    def cross_ref_passed(row):\n",
    "        key = (row[sample],row[qtag],row[barcode])\n",
    "        if key in passed_indexed.index:\n",
    "            row.loc[:,percent_mcounts+'_thresholded'] = passed_indexed.loc[key,percent_mcounts]\n",
    "            row.loc[:,'passed_threshold'] = True\n",
    "        return row\n",
    "\n",
    "    passed_indexed = passeddf.set_index([sample,qtag,barcode])\n",
    "    filtered.rename(columns={percent_mcounts:percent_mcounts+'_filtered'})\n",
    "    filtered.loc[:,'passed_threshold'] = False\n",
    "    filtered.loc[:,percent_mcounts+'_thresholded'] = 0\n",
    "    filtered = filtered.apply(cross_ref_passed, axis=1)\n",
    "    return filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTE SCRIPT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vwl698\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Sample 1 of 19 (1): [ 0.         -1.22736749 -0.12010561  0.         -0.03516536 -0.16175373\n",
      " -0.04850474 -0.02814953 -0.04978995 -0.03925777 -0.10458841  0.\n",
      " -0.31812322 -0.08603313 -0.63092975 -0.5849625   0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "22"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'first_derives' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-97459c0a3213>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfiltered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFILTERED_FILEPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Run thresholding of all samples in dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpasseddf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_threshold_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#     save_data(filtered, passeddf, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-50496c687ecc>\u001b[0m in \u001b[0;36mrun_threshold\u001b[1;34m(d, sample, qtag, barcode, mcounts, reads, percent_mcounts, min_reads, min_mcount)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'barcode_error'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'is_padding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mpassed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mall_threshold_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtlogs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-934198d0e22f>\u001b[0m in \u001b[0;36mthreshold\u001b[1;34m(group, reps_remaining, thresh_mcounts, threshold_log, mcounts)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mmcount_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'passed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_padding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmcounts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnew_thresh_mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmcount_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# if reached steady state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-b6322a1ace8b>\u001b[0m in \u001b[0;36mcalculate_threshold\u001b[1;34m(y, by, mcounts)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mzeroes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_derivs\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mcutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeroes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzeroes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_derivs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_derives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mfirst_derivs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_derives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'first_derives' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Check all inputs exist and are valid\n",
    "    check_inputs()\n",
    "    # Runs data loading in script\n",
    "    filtered = load_data(FILTERED_FILEPATH)\n",
    "    # Run thresholding of all samples in dataset\n",
    "    passeddf, all_threshold_logs = run_threshold(filtered)\n",
    "#     save_data(filtered, passeddf, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "1          1\n",
       "180-10    17\n",
       "180-12    15\n",
       "2          1\n",
       "23         1\n",
       "26         1\n",
       "27         1\n",
       "28         3\n",
       "29         1\n",
       "3          2\n",
       "4          1\n",
       "5          1\n",
       "7          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passeddf.loc[passeddf['passed']==True].groupby('idx').apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fconcat = pd.concat([d[1] for d in filtered if d[0][:2]!=\"VL\" ])\n",
    "# merged = fconcat.merge(passeddf, \n",
    "#               on=['idx','qtag','barcode','mcountsPF','readsPF'], \n",
    "#                        how='outer')\n",
    "# merged.drop(['percent_mcountsPF_x','is_padding'],axis=1, inplace=True)\n",
    "# merged.rename(columns={'percent_mcountsPF_y':\"percent_mcountsPF\"}, inplace=True)\n",
    "# merged = merged.fillna(value={'passed':False,'qtag_error':False,'barcode_error':False,\n",
    "#                     'percent_mcountsPF':0.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# passeddf.loc[passeddf['passed']==True].groupby('idx').apply(len)\n",
    "passeddf.to_csv(\"%s/thresholded-%s.csv\"%(OUTPUT_DIRECTORY,EXPERIMENT), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lib_name = 'samples'\n",
    "# # custom to fix error\n",
    "# # passeddf['newidx'] = passeddf.idx.apply(lambda x: \"%s-%s%s\"%(lib_name, \"0\" if len(x)<7 else \"\", x.split('18014')[-1]))\n",
    "# passeddf['newidx'] = passeddf.idx.apply(lambda x: \"%s-%s%s\"%(\n",
    "#         lib_name, \"0\" if len(x.split(\"-\")[-1])<2 else \"\", x.split('-')[-1]))\n",
    "# passeddf.idx = passeddf.newidx\n",
    "# passeddf.drop(\"newidx\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "passeddf.loc[(passeddf['passed']==True)]\n",
    "#              |(passeddf.mcountsPF>500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shortdf = passeddf.loc[passeddf['passed']==True].copy()\n",
    "shortdf.drop([\"passed\",'qtag_error','barcode_error','is_padding'], axis=1, inplace=True)\n",
    "shortdf = shortdf.loc[shortdf.mcountsPF>100]\n",
    "shortdf.reset_index(inplace=True,drop=True)\n",
    "# shortdf['idx'] = shortdf.idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manual wrangling to remove false positives\n",
    "def apply_calculate_percent_molecs(g):\n",
    "    total = g.mcountsPF.values.sum()/100.\n",
    "    g[PERCENT_MCOUNTS] = g.mcountsPF.apply(lambda x: x/total)\n",
    "    return g\n",
    "shortdf = shortdf.groupby('idx').apply(apply_calculate_percent_molecs)\n",
    "shortdf.sort_values(by=['idx','percent_mcountsPF'],ascending=[1,0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortdf.to_csv('%s/passed-%s.csv'%(OUTPUT_DIRECTORY, EXPERIMENT), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plots scatter\n",
    "for idx, group in filtered_concat.groupby('idx'):\n",
    "    g = group.sort_values(by='mcounts_PF',ascending=False)\n",
    "    counts = g.mcounts_PF.values\n",
    "    itypes = g.qb_type.values\n",
    "\n",
    "    f, ax = plt.subplots(1)\n",
    "    # 0 == passed\n",
    "    # 1 == fail (not mismatch)\n",
    "    # 2 == fail (mismatch)\n",
    "    for i in [0,1,2]:\n",
    "        x = []\n",
    "        y = []\n",
    "        j = 0\n",
    "        typecount = 0\n",
    "        while j < len(counts):\n",
    "            if itypes[j]==i and counts[j]>1:\n",
    "                x.append(j)\n",
    "                y.append(counts[j])\n",
    "                typecount += 1\n",
    "            j+=1\n",
    "        label = \"%s: %d\"%(labels[i],typecount)\n",
    "        alpha = 1\n",
    "        ax.bar(x, y, fill=ctypes[i], alpha=alpha, label=label,\n",
    "                  lw=0)\n",
    "        ax.scatter(x, y, color=ctypes[i], alpha=alpha, label=label,\n",
    "                  marker='.', lw=2)\n",
    "\n",
    "    thresh =max(np.where(itypes==0)[0]) \n",
    "    ax.plot([thresh,thresh],[1,max(counts)], color = ctypes[0], label='%d QB > threshold'%len(np.where(itypes==0)[0]))\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim(0)\n",
    "    ax.legend()\n",
    "    ax.set_title(idx)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itypes = {\n",
    "    (True,False,False):'passed', #passed\n",
    "    (False,True,False):'qtag mismatch', #qtag error\n",
    "    (False,False,True):'barcode oneoff', #barcode error\n",
    "    (False,False,False):'other error', #not one-off\n",
    "    (False,True,True):'other error'\n",
    "}\n",
    "\n",
    "for itype in itypes:\n",
    "    keys = ['passed','qtag_error','barcode_error']\n",
    "    ca = [(merged[k]==v) for k,v in zip(keys,itype)]\n",
    "    cond = ca[0]&ca[1]&ca[2]\n",
    "    merged.loc[(cond),'itype'] = itypes[itype]\n",
    "    \n",
    "ctypes = {\n",
    "    'passed':'#11BF08',\n",
    "    'barcode oneoff': '#DE092B',\n",
    "    'qtag mismatch':'#EBA709',\n",
    "    'other error':'#2A52D5'\n",
    "}\n",
    "itype_order = [\n",
    "    'passed',\n",
    "    'other error',\n",
    "    'barcode oneoff',\n",
    "    'qtag mismatch'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots scatter\n",
    "plottype = 'bar'\n",
    "mcounts=MCOUNTS\n",
    "counter = 0\n",
    "for idx, group in merged.groupby('idx'):\n",
    "#     if idx[:2]=='NH':\n",
    "    if group[mcounts].sum()>1000:\n",
    "        gslice = group.sort_values(by=mcounts,ascending=False)\n",
    "        gslice = gslice.loc[gslice[mcounts]>1]\n",
    "        counts = gslice[mcounts].values\n",
    "        itypes = gslice.itype.values\n",
    "        it_present= np.unique(itypes)\n",
    "        \n",
    "        f, ax = plt.subplots(1)\n",
    "        for itype in itype_order:\n",
    "            if itype in it_present:\n",
    "                x = np.where(itypes==itype)[0]\n",
    "                y = counts[x]\n",
    "                label = \"%s: %d\"%(itype,len(x))\n",
    "                color = ctypes[itype]\n",
    "                alpha = 0.5 if itype in ['passed','other error'] else 1\n",
    "                edgecolor=color\n",
    "                lw = 1.5\n",
    "                s = 250 if itype in ['barcode oneoff','qtag mismatch'] else 8\n",
    "                marker = \"|\" if itype in ['barcode oneoff','qtag mismatch'] else \"-o-\"\n",
    "                    \n",
    "                if plottype == 'scatter':\n",
    "                    ax.scatter(x+1, y, color=color, edgecolors=edgecolor,\n",
    "                            alpha=alpha, label=label, \n",
    "                            marker=marker, lw=lw, s=s)\n",
    "                    \n",
    "                else:\n",
    "                    ax.bar(x, y, color=color, alpha=alpha, \n",
    "                           label=label, lw=0, width=1 )\n",
    "        \n",
    "        thresh_values = all_threshold_logs[idx]\n",
    "        thresh_line_fmts = [1, 0.5]\n",
    "        last_round = 1\n",
    "        last_val = 0\n",
    "        for tline in range(1,len(thresh_values)):\n",
    "            \n",
    "            thresh_line = thresh_values[tline] \n",
    "            if thresh_line != last_val:\n",
    "                print idx,tline, thresh_line\n",
    "    #             thresh_line =np.max(np.where(itypes=='passed')[0])+1\n",
    "    #             alpha = thresh_line_fmts[len(thresh_values)-tline-1]\n",
    "                alpha = 1\n",
    "                ax.plot([thresh_line,thresh_line],[1,max(counts)], \n",
    "                        color = 'black', alpha = 1, ls = '--',\n",
    "                        label='%d QB > threshold iter %d'%(thresh_line, last_round))\n",
    "                last_val = thresh_line\n",
    "                last_round += 1\n",
    "        thresh_line =np.max(np.where(itypes=='passed')[0])+1\n",
    "        ax.plot([thresh_line,thresh_line],[1,max(counts)], \n",
    "                color = 'black', alpha = 1, ls = '--',\n",
    "                label='%d QB > threshold iter %d'%(thresh_line, last_round))\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(0)\n",
    "        ax.legend()\n",
    "        ax.set_title(idx)\n",
    "        f.savefig('../output/%s_%s.png'%(EXPERIMENT, idx))\n",
    "#         break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#####  Color Palette by Paletton.com\n",
    "#####  Palette URL: http://paletton.com/#uid=c3P112O5x0kuKtzjHyVsYK-v+n-Cvj1\n",
    "\n",
    "1.  BLUE    other error\n",
    "2.  GREEN   passed\n",
    "3.  RED     barcode oneoff\n",
    "4.  YELLOW  qtag mismatch\n",
    "\n",
    "*** Primary color:\n",
    "\n",
    "   shade 0 = #18379F = rgb( 24, 55,159) = rgba( 24, 55,159,1) = rgb0(0.094,0.216,0.624)\n",
    "   shade 1 = #5269B4 = rgb( 82,105,180) = rgba( 82,105,180,1) = rgb0(0.322,0.412,0.706)\n",
    "   >>>>shade 2 = #2A52D5 = rgb( 42, 82,213) = rgba( 42, 82,213,1) = rgb0(0.165,0.322,0.835)<<<<\n",
    "   shade 3 = #0F297F = rgb( 15, 41,127) = rgba( 15, 41,127,1) = rgb0(0.059,0.161,0.498)\n",
    "   shade 4 = #091F67 = rgb(  9, 31,103) = rgba(  9, 31,103,1) = rgb0(0.035,0.122,0.404)\n",
    "\n",
    "*** Secondary color (1):\n",
    "\n",
    "   shade 0 = #11BF08 = rgb( 17,191,  8) = rgba( 17,191,  8,1) = rgb0(0.067,0.749,0.031)\n",
    "   shade 1 = #58D351 = rgb( 88,211, 81) = rgba( 88,211, 81,1) = rgb0(0.345,0.827,0.318)\n",
    "   shade 2 = #20E616 = rgb( 32,230, 22) = rgba( 32,230, 22,1) = rgb0(0.125,0.902,0.086)\n",
    "   shade 3 = #089800 = rgb(  8,152,  0) = rgba(  8,152,  0,1) = rgb0(0.031,0.596,0)\n",
    "   shade 4 = #067B00 = rgb(  6,123,  0) = rgba(  6,123,  0,1) = rgb0(0.024,0.482,0)\n",
    "\n",
    "*** Secondary color (2):\n",
    "\n",
    "   shade 0 = #DE092B = rgb(222,  9, 43) = rgba(222,  9, 43,1) = rgb0(0.871,0.035,0.169)\n",
    "   shade 1 = #F25D75 = rgb(242, 93,117) = rgba(242, 93,117,1) = rgb0(0.949,0.365,0.459)\n",
    "   shade 2 = #F8183B = rgb(248, 24, 59) = rgba(248, 24, 59,1) = rgb0(0.973,0.094,0.231)\n",
    "   shade 3 = #B1001C = rgb(177,  0, 28) = rgba(177,  0, 28,1) = rgb0(0.694,0,0.11)\n",
    "   shade 4 = #8F0017 = rgb(143,  0, 23) = rgba(143,  0, 23,1) = rgb0(0.561,0,0.09)\n",
    "\n",
    "*** Complement color:\n",
    "\n",
    "   shade 0 = #EBA709 = rgb(235,167,  9) = rgba(235,167,  9,1) = rgb0(0.922,0.655,0.035)\n",
    "   shade 1 = #FFCF62 = rgb(255,207, 98) = rgba(255,207, 98,1) = rgb0(1,0.812,0.384)\n",
    "   shade 2 = #FFB918 = rgb(255,185, 24) = rgba(255,185, 24,1) = rgb0(1,0.725,0.094)\n",
    "   shade 3 = #BC8300 = rgb(188,131,  0) = rgba(188,131,  0,1) = rgb0(0.737,0.514,0)\n",
    "   shade 4 = #986900 = rgb(152,105,  0) = rgba(152,105,  0,1) = rgb0(0.596,0.412,0)\n",
    "\n",
    "\n",
    "#####  Generated by Paletton.com (c) 2002-2014"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
