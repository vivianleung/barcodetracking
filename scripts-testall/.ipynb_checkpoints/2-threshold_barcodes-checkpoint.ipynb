{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Experiment name to prepend output files\"\"\"\n",
    "EXPERIMENT = \"18014\"\n",
    "\n",
    "\"\"\"Directory path to input data \n",
    "    (filtered; output from '1-read_fastq_id_features)\n",
    "\"\"\"\n",
    "FILTERED_FILEPATH = \"../output-testall/filtered-18014-valid.csv\"\n",
    "\n",
    "\"\"\"Directory path to save output\"\"\"\n",
    "OUTPUT_DIRECTORY = \"../output-testall\"\n",
    "\n",
    "\"\"\"Minimum number of reads as a baseline. Used to simplify data processing.\"\"\"\n",
    "MIN_READS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESETS AND SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Column names correspoinding to eponymous variables\"\"\"\n",
    "\n",
    "SAMPLE = 'idx'\n",
    "QTAG = 'qtag'\n",
    "BARCODE = 'barcode'\n",
    "READS = 'readsPF'\n",
    "MCOUNTS = 'mcountsPF'\n",
    "PERCENT_MCOUNTS = 'percent_%s'%MCOUNTS\n",
    "GROUPBY = ['idx']\n",
    "\n",
    "# for older versions/ formats\n",
    "# SAMPLE = 'idx'\n",
    "# QTAG = 'qtag'\n",
    "# BARCODE = 'gtag'\n",
    "# READS = 'reads'\n",
    "# MCOUNTS = 'molecs'\n",
    "# PERCENT_MCOUNTS = 'percent_%s'%MCOUNTS\n",
    "# GROUPBY = ['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_inputs():\n",
    "    \n",
    "    # modules\n",
    "    assert pd\n",
    "    assert np\n",
    "    assert regex\n",
    "    assert os\n",
    "    assert sys\n",
    "    \n",
    "    # user experiment inputs \n",
    "    assert EXPERIMENT\n",
    "    assert FILTERED_FILEPATH\n",
    "    assert OUTPUT_DIRECTORY\n",
    "    assert MIN_READS\n",
    "    \n",
    "    # user columns\n",
    "    assert SAMPLE\n",
    "    assert QTAG\n",
    "    assert BARCODE\n",
    "    assert READS\n",
    "    assert MCOUNTS\n",
    "    assert PERCENT_MCOUNTS\n",
    "    assert GROUPBY\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_percent_molecs(df, mcounts=MCOUNTS, percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Updates percent molec counters for sample\"\"\"\n",
    "    total = float(df[mcounts].values.sum()) / 100.\n",
    "    df[percent_mcounts] = df[mcounts].apply(lambda x: x/total)\n",
    "    df = df.sort_values(by=mcounts, ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filtered_file, sample=SAMPLE, qtag=QTAG, \n",
    "              barcode=BARCODE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Loads filtered lib-ID-barcode data csv to dict of samples\"\"\"\n",
    "    columns = [sample, qtag, barcode, mcounts, reads]\n",
    "    # loads excel file (all tabs)\n",
    "    try:\n",
    "        csv = pd.read_csv(filtered_file, sep=',')\n",
    "    except:\n",
    "        csv = pd.read_csv(filtered_file, sep='\\t')\n",
    "    # filter out null barcodes just in case (if custom user input)\n",
    "    csv = csv.loc[(csv[qtag]!='None') & (csv[barcode]!='None')]\n",
    "    csv = csv[columns]\n",
    "    csv[sample] = csv[sample].apply(lambda x: str(x))\n",
    "    # get percent molecs per sample, store as output dict entry \n",
    "    groups = csv.groupby(sample)\n",
    "    data = []\n",
    "    for i, group in csv.groupby(sample):\n",
    "        data.append((i,calculate_percent_molecs(group)))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_data(d, sample=SAMPLE, mcounts=MCOUNTS, reads=READS):\n",
    "    \"\"\"Check data for proper format, input values, and \n",
    "    converts into list-like object if necessary\n",
    "\n",
    "    d(list, np.array ,dict, or pd.DataFrame): input data\n",
    "    \n",
    "    Returns: data set as a list-like object, wherein\n",
    "        each item is a pair containing sample name (str) and \n",
    "        sample data (pd.DataFrame), in that order.\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "    # wrangle data to list of list-like pairs, as \"[idx, df]\"\n",
    "    if type(d) in [np.array, list] :\n",
    "        data_arr = d\n",
    "    elif type(d) == dict:\n",
    "        data_arr = d.items()\n",
    "    elif type(d) == pd.DataFrame :\n",
    "        data_arr = [(s,df) for s,df in d.groupby(sample)]\n",
    "    else:\n",
    "        print \"Input data is not in correct format. Please provide \\\n",
    "        list-like, dict, or pd.DataFrame object.\"\n",
    "    \n",
    "    # check input has correct values\n",
    "    try:\n",
    "        for a in data_arr:\n",
    "            assert len(a) == 2, \"incorrect item length\"\n",
    "            s, df = a\n",
    "            assert type(s) == str, 'sample name is not string type'\n",
    "            assert type(df) == pd.DataFrame, \"incorrect value type: must be pd.DataFrame\"\n",
    "            assert sample in df.columns, \"%s not in dataframe\"%sample\n",
    "            assert mcounts in df.columns, \"%s not in dataframe\"%mcounts\n",
    "            assert reads in df.columns, \"%s not in dataframe\"%reads\n",
    "    # if no \n",
    "    except IndexError as e:\n",
    "        print \"Item number of values is not 2.\\n\"\n",
    "        print \"IndexError. \",e.message\n",
    "        print a\n",
    "    except ValueError as e:\n",
    "        print \"Sample name could not be converted to float: %s\\n\"% type(item[i])\n",
    "        print \"ValueError. \",e.message\n",
    "        print a\n",
    "    except AssertionError as e:\n",
    "        print \"Assertion failed:\"\n",
    "        print e.message\n",
    "        print a\n",
    "    \n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def threshold(group, reps_remaining, thresh_val, thresh_i,\n",
    "             percent_mcounts=PERCENT_MCOUNTS, mcounts=MCOUNTS):\n",
    "    \"\"\"Thresholds barcodes of a given sample\n",
    "\n",
    "        group(pd.DataFrame): df containing library-ID-barcodes, \n",
    "            mcountsPF and percent_mcountsPF\n",
    "        reps_remaining(int): reps remaining from max number \n",
    "            input from user \n",
    "        thresh_val(float or int): initial threshold value (percent_mcountPF)\n",
    "            provided from previous recursion or user input\n",
    "        thresh_i(int): initial position of threshold value in \n",
    "            percent_mcountsPF list, ranging [0,len(group))\n",
    "\n",
    "        Returns: \n",
    "            None, if thresholding fails;\n",
    "            passed(pd.DataFrame), if thresholding successful; or\n",
    "            self, otherwise, with updated threshold values and \n",
    "                group df.\n",
    "    \"\"\"\n",
    "    # max out reps\n",
    "    if reps_remaining <= 0:\n",
    "        print 'Maxed out reps. Skipping sample.'\n",
    "    # no barcodes passed threshold \n",
    "    elif len(group) == 0:\n",
    "        print \"No barcodes passed threshold. Skipping sample.\"\n",
    "    else:\n",
    "        # calculate new threshold \n",
    "        \n",
    "        # line add 2016-10-12 to pre-sort values\n",
    "        group.sort_values(by=mcounts, ascending=False, inplace=True)\n",
    "        # existing\n",
    "        group = calculate_percent_molecs(group)\n",
    "        calc_threshold_i = calculate_threshold(group[mcounts].values)\n",
    "        new_thresh_i = min(calc_threshold_i, len(group)-1)\n",
    "        new_thresh_val = group[percent_mcounts].values[new_thresh_i]\n",
    "#         print \"\\nTOP OF THRESHOLD \"\n",
    "#         print 'group len', len(group)\n",
    "#         print 'thresh_val', thresh_val\n",
    "#         print 'thresh_i', thresh_i\n",
    "#         print 'calc_threshold_i', calc_threshold_i\n",
    "#         print 'new_thresh_i', new_thresh_i\n",
    "#         print 'new_thresh_val',new_thresh_val, '\\n'\n",
    "        \n",
    "        # if reached steady state\n",
    "        if new_thresh_val == thresh_val:\n",
    "            # get rid of any \"padding\" barcodes (see eliminate_oneoffs fn)\n",
    "            # line added 2016-10-12 to remove barcodes that didn't pass threshold\n",
    "            passed_temp = group.loc[(group.is_padding==False) & (group[percent_mcounts]>=new_thresh_val)]\n",
    "            \n",
    "            passed = calculate_percent_molecs(passed_temp)\n",
    "            # update percent molecs\n",
    "            passed.reset_index(inplace=True,drop=True)\n",
    "#             print 'barcodes', len(group)\n",
    "            sys.stdout.write('Thresholded.\\n')\n",
    "                       \n",
    "            return passed\n",
    "        # recursively clean and re-threshold\n",
    "        else:\n",
    "            # clean up group by eliminating one-offs\n",
    "            \n",
    "            group = calculate_percent_molecs(group)\n",
    "            cleaned = eliminate_oneoffs(group,new_thresh_val)\n",
    "            cleaned.reset_index(inplace=True,drop=True)\n",
    "            # recurse with cleaned df and new threshold values\n",
    "            return threshold(cleaned, reps_remaining-1, new_thresh_val, \n",
    "                             new_thresh_i, percent_mcounts=percent_mcounts, \n",
    "                             mcounts=mcounts)\n",
    "        \n",
    "    # if thresholding failed, return None\n",
    "    sys.stdout.write('Skipped.\\n')\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 2: CALCULATE THRESHOLD via. CONCAVITY\n",
    "\n",
    "\n",
    "def calculate_threshold(y):\n",
    "    \"\"\"Calculates threshold of series with modified concavity approach\n",
    "\n",
    "        y(np.array or list): list or list-like object of \n",
    "            values as floats or ints\n",
    "\n",
    "        Returns index of inflection point in array, \n",
    "            i.e. threshold position.\n",
    "    \"\"\"\n",
    "    def rolling_window(arr):\n",
    "        \"\"\"Constructs list of overlapping subarray ranges of size 2\"\"\"\n",
    "        shape = arr.shape[:-1] + (arr.shape[-1]-1, 2)\n",
    "        strides = arr.strides + (arr.strides[-1],)\n",
    "        windows = np.lib.stride_tricks.as_strided(arr, \n",
    "                              shape=shape, strides=strides)\n",
    "        return windows\n",
    "    def first_d_gen(windows):\n",
    "        \"\"\"Generates first derivative of windows as relative difference\"\"\"\n",
    "        for w in windows:\n",
    "            # amended 2016-10-12: normalize by y midpoint instead of second point to \n",
    "            # better represent the count magnitude of segment\n",
    "            yield float(w[1]-w[0])/(w[0]+w[1])*2\n",
    "    def second_d_gen(windows):\n",
    "        \"\"\"Generates second derivative of windows\"\"\"\n",
    "        for w in windows:\n",
    "            yield w[1]-w[0]         \n",
    "    \n",
    "    y_temp = sorted(y, reverse=True)\n",
    "#     if False in [yi==y_tempi for yi, y_tempi in zip(y, y_temp)]:\n",
    "#         print \"DIFFERENT!\"\n",
    "    # left and right padding to cover all array vals in derivations\n",
    "    yarray = np.concatenate([ [y_temp[0]], y_temp, [1] ])\n",
    "    # calculates first derivative\n",
    "    first_windows = rolling_window(yarray)\n",
    "    first_derivs = np.fromiter(first_d_gen(first_windows), np.float\n",
    "                               , count=len(first_windows))\n",
    "    # calculates second derivative\n",
    "    second_windows = rolling_window(first_derivs)\n",
    "    second_derivs = np.fromiter(second_d_gen(second_windows), np.float\n",
    "                                , count=len(second_windows))\n",
    "    # gets index or position value of inflection point (curves down ), adjust by adding 1\n",
    "    # for second deriv\n",
    "    thresh_i = np.argmin(second_derivs)+1\n",
    "    \n",
    "#     print \"\\nCALCULATE THRESHOLD\"\n",
    "#     print \"2nd max\", np.argmax(second_derivs), np.max(second_derivs)\n",
    "#     print \"2nd min\", np.argmin(second_derivs), np.min(second_derivs)\n",
    "#     print \"\\n\"\n",
    "    return thresh_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eliminate_oneoffs(group, thresh_val, pad=True,\n",
    "                      qtag=QTAG, barcode=BARCODE, percent_mcounts=PERCENT_MCOUNTS, \n",
    "                      mcounts=MCOUNTS):\n",
    "    \"\"\"Eliminate barcodes that are one position off from a more-abundant barcode\n",
    "        group(pd.DataFrame): df containing qtag, barcode, and percent_mcounts columns\n",
    "        thresh_val(float): threshold value to select high abundant barcodes\n",
    "            to iterate through as 'major' ones\n",
    "        pad(bool): if True, adds a right pad so last non-eliminated value \n",
    "            can be analyzed in by the threshold() function. Default True.\n",
    "        qtag, barcode, percent_mcounts, mcounts (str): column names for the corresponding\n",
    "            argument. Defaults are global vars QTAG, BARCODE, PERCENT_MCOUNTS, MCOUNTS.\n",
    "\n",
    "        Returns: table of barcodes that passed elimination\n",
    "    \"\"\"\n",
    "    group.loc[:,'delete'] = group[mcounts].apply(lambda _: False)\n",
    "    group.loc[:,'is_padding'] = group[mcounts].apply(lambda _: False)\n",
    "    counter = 0\n",
    "    # add capability to check other parameters, i.e. qtag\n",
    "    for majorI, majorRow in group.loc[group[percent_mcounts] > thresh_val].iterrows():\n",
    "        # if it has not yet been tested\n",
    "        if majorRow.delete == False:\n",
    "            subgroup = group[counter+1:].loc[(group.delete==False)]\n",
    "            # for each 'minor' barcode aka. with fewer molecs, test if one-off from major\n",
    "            for minorI, minorRow in subgroup.iterrows():\n",
    "                query = regex.search(\"(%s){s<=1}\" % majorRow[barcode],\n",
    "                                     minorRow[barcode])\n",
    "                if query:\n",
    "                    group.loc[minorI,'delete'] = True\n",
    "        counter+=1\n",
    "        \n",
    "    # select barcodes which pass, ie. are not eliminated\n",
    "    output = group.loc[(group.delete==False) & (group[percent_mcounts] >= thresh_val)]\n",
    "#     print \"\\nEND OF ELIMINATE ONEOFFS\"\n",
    "#     print len(output)\n",
    "    # if requested, adds a right pad  \n",
    "    # line added 2016-10-12: combine two conditions: ensure that \n",
    "    # no null rows get added if all barcodes are accepted\n",
    "    if pad==True and len(group) != len(group.delete==False):\n",
    "        deletes = group.loc[(group.delete==True) & (group[percent_mcounts]<thresh_val)][mcounts]\n",
    "#         if len(deletes) > 0:\n",
    "        max_i = deletes.idxmax()\n",
    "        output.append(group.loc[max_i,:])\n",
    "        output.loc[max_i,['delete', 'is_padding']] = [False, True]\n",
    "#     print output.head(), \"\\n\"\n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_threshold(d, sample=SAMPLE, qtag=QTAG, barcode=BARCODE, \n",
    "                  mcounts=MCOUNTS, reads=READS, percent_mcounts=PERCENT_MCOUNTS,\n",
    "                  min_reads=MIN_READS, min_mcount=50):\n",
    "    \"\"\"Run threshold algorithm for each sample in dataset\n",
    "\n",
    "        d(np.array, list, dict, or pd.DataFrame): dataset for all samples\n",
    "        sample, qtag, barcode, mcounts, reads, percent_mcounts(str): columns in df for \n",
    "            corresponding vals. Defaults are global vars SAMPLE, QTAG, BARCODE, MCOUNTS, \n",
    "            READS, PERCENT_MCOUNTS.\n",
    "        min_reads(int): minimum number of reads for a library-ID-barcode as an \n",
    "            absolute baseline (that which any barcode below is highly likely to be \n",
    "            false.) Default is global var MIN_READS.\n",
    "        min_mcount(int): minimum number of molecs for library-ID-barcode as an\n",
    "            absolute baseline. Default is 50.\n",
    "\n",
    "        Note: min_reads and min_mcount are applied to increase performance.\n",
    "\n",
    "        Returns: \n",
    "            pd.DataFrame, if successful, of 'true' (passed) library-ID-barcodes \n",
    "                for all samples\n",
    "            None, if no samples had passing library-ID-barcodes.\n",
    "    \"\"\"\n",
    "    passed = []\n",
    "    counter = 1\n",
    "    # checks and formats data (d) to list-like obj of pairs\n",
    "    data_arr = check_data(d, sample=sample, mcounts=mcounts, reads=reads)\n",
    "    # run for each (sample, df) in dataset \n",
    "    for s, group in data_arr:\n",
    "#         print '\\n\\n>>>>> NEW INDEX'\n",
    "        sys.stdout.write(\"Sample %d of %d (%s): \"%(counter,len(data_arr),s))\n",
    "        # select valid data meeting absolute baseline \n",
    "        group = group.loc[(group[qtag] != 'None') & (group[barcode] != 'None') \n",
    "                          & (group[mcounts] > min_mcount)\n",
    "                          & (group[reads] > min_reads)]\n",
    "        result = threshold(group, 20, -1, len(group)+2)\n",
    "        passed.append(result)\n",
    "        sys.stdout.flush()\n",
    "        counter += 1\n",
    "    # if we do have data (i.e. some barcodes that passed in the samples)\n",
    "    if len(passed) > 0:\n",
    "        # concat all df together\n",
    "        passeddf = pd.concat(passed)\n",
    "        # formatting\n",
    "        passeddf.sort_values(by=[sample,percent_mcounts]\n",
    "                             ,ascending=[True, False]\n",
    "                             ,inplace=True)\n",
    "        passeddf.drop(['delete','is_padding'], axis=1, inplace=True)\n",
    "        passeddf.reset_index(inplace=True,drop=True)\n",
    "        return passeddf\n",
    "    else:\n",
    "        print \"No samples were successfully thresholded.\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRIPT TO SAVE DATA TO CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(filtered,passed, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT):\n",
    "    \n",
    "    # Save passed dataframe\n",
    "    passed.to_csv('%s/threshold-%s-passed.csv'%(output_directory,experiment), index=False)\n",
    "    # count and save results\n",
    "    counts = count_sample_barcodes(passed)\n",
    "    counts.to_csv('%s/threshold-%s-counts.csv'%(output_directory,experiment), index=False)\n",
    "    # merge passed and filtered data and save\n",
    "    fc_temp = pd.concat([d[1] for d in filtered])\n",
    "    filtered_concat = apply_passed_data(fc_temp, passed)\n",
    "    filtered_concat.to_csv('%s/threshold-%s-merged.csv'%(output_directory,experiment), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_sample_barcodes(df, groupby=SAMPLE, barcode=BARCODE, sample=SAMPLE, qtag=QTAG\n",
    "                      , percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Counts passed barcodes per sample and saves as csv\n",
    "    \n",
    "        df(pd.DataFrame): input dataframe containing passed \n",
    "            barcodes of all samples\n",
    "        groupby(str or list-like): columns to group samples by\n",
    "    \"\"\"\n",
    "    agg = df.groupby(groupby).agg(len)\n",
    "    counts = agg[agg.columns[0]]\n",
    "    counts.name = 'count'\n",
    "    counts = pd.DataFrame(counts)\n",
    "    counts.reset_index(inplace=True)\n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_passed_data(filtered, passed, sample=SAMPLE, qtag=QTAG\n",
    "                      , barcode=BARCODE, percent_mcounts=PERCENT_MCOUNTS):\n",
    "    \"\"\"Cross reference passed barcodes with raw filtered data\n",
    "        filtered(pd.DataFrame): raw filtered data as dataframe for all samples\n",
    "        passed(pd.DataFrame): data passed threshold (output of run_threshold)\n",
    "        sample,qtag,barcode,percent_mcounts(str): names corresponding to df columns.\n",
    "            Defaults are SAMPLE,QTAG,BARCODE,PERCENT_MCOUNTS.\n",
    "\n",
    "        Returns:\n",
    "            filtered(pd.DataFrame) updated with 'passed_threshold' and \n",
    "            percent_mcounts columns\n",
    "    \"\"\"\n",
    "    def cross_ref_passed(row):\n",
    "        key = (row[sample],row[qtag],row[barcode])\n",
    "        if key in passed_indexed.index:\n",
    "            row[percent_mcounts+'_thresholded'] = passed_indexed.loc[key,percent_mcounts]\n",
    "            row['passed_threshold'] = True\n",
    "        return row\n",
    "\n",
    "    passed_indexed = passed.set_index([sample,qtag,barcode])\n",
    "    filtered.rename(columns={percent_mcounts:percent_mcounts+'_filtered'})\n",
    "    filtered['passed_threshold'] = False\n",
    "    filtered[percent_mcounts+'_thresholded'] = 0\n",
    "    filtered = filtered.apply(cross_ref_passed, axis=1)\n",
    "    return filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTE SCRIPT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivianleung/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/vivianleung/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 of 19 (1): Thresholded.\n",
      "Sample 2 of 19 (180-10): Thresholded.\n",
      "Sample 3 of 19 (180-12): Thresholded.\n",
      "Sample 4 of 19 (2): Thresholded.\n",
      "Sample 5 of 19 (20): Thresholded.\n",
      "Sample 6 of 19 (21): Thresholded.\n",
      "Sample 7 of 19 (22): Thresholded.\n",
      "Sample 8 of 19 (23): Thresholded.\n",
      "Sample 9 of 19 (24): Thresholded.\n",
      "Sample 10 of 19 (25): Thresholded.\n",
      "Sample 11 of 19 (26): Thresholded.\n",
      "Sample 12 of 19 (27): Thresholded.\n",
      "Sample 13 of 19 (28): Thresholded.\n",
      "Sample 14 of 19 (29): Thresholded.\n",
      "Sample 15 of 19 (3): Thresholded.\n",
      "Sample 16 of 19 (4): Thresholded.\n",
      "Sample 17 of 19 (5): Thresholded.\n",
      "Sample 18 of 19 (6): Thresholded.\n",
      "Sample 19 of 19 (7): Thresholded.\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Check all inputs exist and are valid\n",
    "    check_inputs()\n",
    "    # Runs data loading in script\n",
    "    filtered = load_data(FILTERED_FILEPATH)\n",
    "    # Run thresholding of all samples in dataset\n",
    "    passed = run_threshold(filtered)\n",
    "    save_data(filtered, passed, output_directory=OUTPUT_DIRECTORY, experiment=EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx\n",
       "1          1\n",
       "180-10    11\n",
       "180-12     2\n",
       "2          1\n",
       "20         1\n",
       "21         1\n",
       "22         1\n",
       "23         1\n",
       "24         1\n",
       "25         1\n",
       "26         1\n",
       "27         1\n",
       "28         3\n",
       "29         1\n",
       "3          2\n",
       "4          1\n",
       "5          1\n",
       "6          1\n",
       "7          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passed['idx'] = passed.idx.astype(int)\n",
    "passed.groupby('idx').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>qtag</th>\n",
       "      <th>barcode</th>\n",
       "      <th>mcountsPF</th>\n",
       "      <th>readsPF</th>\n",
       "      <th>percent_mcountsPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1</td>\n",
       "      <td>q25</td>\n",
       "      <td>TTGCTTC</td>\n",
       "      <td>21979</td>\n",
       "      <td>23011</td>\n",
       "      <td>98.094260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>180-10</td>\n",
       "      <td>q19</td>\n",
       "      <td>TTGTGGC</td>\n",
       "      <td>3516</td>\n",
       "      <td>4600</td>\n",
       "      <td>58.077304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>180-10</td>\n",
       "      <td>q24</td>\n",
       "      <td>CGGTGTG</td>\n",
       "      <td>878</td>\n",
       "      <td>1104</td>\n",
       "      <td>14.502808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180-12</td>\n",
       "      <td>q19</td>\n",
       "      <td>TTGTGGC</td>\n",
       "      <td>1453</td>\n",
       "      <td>1616</td>\n",
       "      <td>53.874676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180-12</td>\n",
       "      <td>q24</td>\n",
       "      <td>CGGTGTG</td>\n",
       "      <td>707</td>\n",
       "      <td>746</td>\n",
       "      <td>26.214312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2</td>\n",
       "      <td>q24</td>\n",
       "      <td>GGTTGAT</td>\n",
       "      <td>61172</td>\n",
       "      <td>68931</td>\n",
       "      <td>98.488190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>q19</td>\n",
       "      <td>GATCCAT</td>\n",
       "      <td>189720</td>\n",
       "      <td>465296</td>\n",
       "      <td>98.851114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>21</td>\n",
       "      <td>q23</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>13552</td>\n",
       "      <td>13456</td>\n",
       "      <td>98.999196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>22</td>\n",
       "      <td>q23</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>166365</td>\n",
       "      <td>339984</td>\n",
       "      <td>98.793328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>23</td>\n",
       "      <td>q24</td>\n",
       "      <td>GCGTCTC</td>\n",
       "      <td>15262</td>\n",
       "      <td>15289</td>\n",
       "      <td>98.687359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>24</td>\n",
       "      <td>q24</td>\n",
       "      <td>GGGATAT</td>\n",
       "      <td>21939</td>\n",
       "      <td>22133</td>\n",
       "      <td>98.606679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>25</td>\n",
       "      <td>q19</td>\n",
       "      <td>TGTATGG</td>\n",
       "      <td>42568</td>\n",
       "      <td>48312</td>\n",
       "      <td>99.004559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>26</td>\n",
       "      <td>q19</td>\n",
       "      <td>TGTATGG</td>\n",
       "      <td>21539</td>\n",
       "      <td>22583</td>\n",
       "      <td>99.139280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>27</td>\n",
       "      <td>q19</td>\n",
       "      <td>ATCCTTT</td>\n",
       "      <td>24880</td>\n",
       "      <td>26404</td>\n",
       "      <td>99.135355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>28</td>\n",
       "      <td>q23</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>28217</td>\n",
       "      <td>29812</td>\n",
       "      <td>41.469365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>28</td>\n",
       "      <td>q19</td>\n",
       "      <td>TGTATGG</td>\n",
       "      <td>21353</td>\n",
       "      <td>21946</td>\n",
       "      <td>31.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>28</td>\n",
       "      <td>q24</td>\n",
       "      <td>GGGATAT</td>\n",
       "      <td>12084</td>\n",
       "      <td>11757</td>\n",
       "      <td>17.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>28</td>\n",
       "      <td>q19</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>1458</td>\n",
       "      <td>1372</td>\n",
       "      <td>2.142763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>28</td>\n",
       "      <td>q23</td>\n",
       "      <td>TGTATGG</td>\n",
       "      <td>1315</td>\n",
       "      <td>1225</td>\n",
       "      <td>1.932601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>28</td>\n",
       "      <td>q24</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>1018</td>\n",
       "      <td>917</td>\n",
       "      <td>1.496113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>28</td>\n",
       "      <td>q24</td>\n",
       "      <td>TGTATGG</td>\n",
       "      <td>791</td>\n",
       "      <td>716</td>\n",
       "      <td>1.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>28</td>\n",
       "      <td>q23</td>\n",
       "      <td>GGGATAT</td>\n",
       "      <td>682</td>\n",
       "      <td>604</td>\n",
       "      <td>1.002307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>28</td>\n",
       "      <td>q19</td>\n",
       "      <td>GGGATAT</td>\n",
       "      <td>601</td>\n",
       "      <td>533</td>\n",
       "      <td>0.883265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>29</td>\n",
       "      <td>q19</td>\n",
       "      <td>GGTGGGC</td>\n",
       "      <td>68425</td>\n",
       "      <td>78713</td>\n",
       "      <td>96.931620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>29</td>\n",
       "      <td>q19</td>\n",
       "      <td>GGTGTGC</td>\n",
       "      <td>584</td>\n",
       "      <td>32</td>\n",
       "      <td>0.827301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>3</td>\n",
       "      <td>q24</td>\n",
       "      <td>GAGTGTG</td>\n",
       "      <td>14220</td>\n",
       "      <td>13854</td>\n",
       "      <td>55.675189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>3</td>\n",
       "      <td>q23</td>\n",
       "      <td>AGTTATT</td>\n",
       "      <td>9876</td>\n",
       "      <td>9396</td>\n",
       "      <td>38.667241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>3</td>\n",
       "      <td>q23</td>\n",
       "      <td>GAGTGTG</td>\n",
       "      <td>614</td>\n",
       "      <td>560</td>\n",
       "      <td>2.403978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>3</td>\n",
       "      <td>q24</td>\n",
       "      <td>AGTTATT</td>\n",
       "      <td>607</td>\n",
       "      <td>532</td>\n",
       "      <td>2.376571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>4</td>\n",
       "      <td>q23</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>28058</td>\n",
       "      <td>30154</td>\n",
       "      <td>99.313323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>5</td>\n",
       "      <td>q19</td>\n",
       "      <td>GAACTTC</td>\n",
       "      <td>103126</td>\n",
       "      <td>149848</td>\n",
       "      <td>99.140550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>6</td>\n",
       "      <td>q23</td>\n",
       "      <td>GTTTCTG</td>\n",
       "      <td>23803</td>\n",
       "      <td>24691</td>\n",
       "      <td>99.415278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>7</td>\n",
       "      <td>q23</td>\n",
       "      <td>ATTGTGT</td>\n",
       "      <td>28025</td>\n",
       "      <td>28960</td>\n",
       "      <td>98.700430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx qtag  barcode  mcountsPF  readsPF  percent_mcountsPF\n",
       "800        1  q25  TTGCTTC      21979    23011          98.094260\n",
       "47    180-10  q19  TTGTGGC       3516     4600          58.077304\n",
       "48    180-10  q24  CGGTGTG        878     1104          14.502808\n",
       "0     180-12  q19  TTGTGGC       1453     1616          53.874676\n",
       "1     180-12  q24  CGGTGTG        707      746          26.214312\n",
       "892        2  q24  GGTTGAT      61172    68931          98.488190\n",
       "303       20  q19  GATCCAT     189720   465296          98.851114\n",
       "443       21  q23  GTTTCTG      13552    13456          98.999196\n",
       "470       22  q23  GTTTCTG     166365   339984          98.793328\n",
       "561       23  q24  GCGTCTC      15262    15289          98.687359\n",
       "128       24  q24  GGGATAT      21939    22133          98.606679\n",
       "172       25  q19  TGTATGG      42568    48312          99.004559\n",
       "223       26  q19  TGTATGG      21539    22583          99.139280\n",
       "254       27  q19  ATCCTTT      24880    26404          99.135355\n",
       "595       28  q23  GTTTCTG      28217    29812          41.469365\n",
       "596       28  q19  TGTATGG      21353    21946          31.381626\n",
       "597       28  q24  GGGATAT      12084    11757          17.759358\n",
       "598       28  q19  GTTTCTG       1458     1372           2.142763\n",
       "599       28  q23  TGTATGG       1315     1225           1.932601\n",
       "600       28  q24  GTTTCTG       1018      917           1.496113\n",
       "601       28  q24  TGTATGG        791      716           1.162500\n",
       "602       28  q23  GGGATAT        682      604           1.002307\n",
       "603       28  q19  GGGATAT        601      533           0.883265\n",
       "720       29  q19  GGTGGGC      68425    78713          96.931620\n",
       "721       29  q19  GGTGTGC        584       32           0.827301\n",
       "837        3  q24  GAGTGTG      14220    13854          55.675189\n",
       "838        3  q23  AGTTATT       9876     9396          38.667241\n",
       "839        3  q23  GAGTGTG        614      560           2.403978\n",
       "840        3  q24  AGTTATT        607      532           2.376571\n",
       "1016       4  q23  GTTTCTG      28058    30154          99.313323\n",
       "950        5  q19  GAACTTC     103126   149848          99.140550\n",
       "1084       6  q23  GTTTCTG      23803    24691          99.415278\n",
       "1046       7  q23  ATTGTGT      28025    28960          98.700430"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fconcat = pd.concat([f[1] for f in filtered])\n",
    "fconcat.loc[fconcat.mcountsPF > 500]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
